{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=True, dataset='Pubmed', debug=True, defense_mode='none', device_id=2, dis_weight=1, dropout=0.5, epochs=1000, evaluate_mode='1by1', hidden=128, homo_boost_thrd=0.8, homo_loss_weight=100, inner=1, k=100, lr=0.01, model='GCN', no_cuda=False, outter_size=4096, prune_thr=0.8, range=1.0, rec_epochs=30, seed=12, selection_method='none', target_class=2, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.01, trigger_size=3, trojan_epochs=400, use_vs_number=True, vs_number=160, vs_ratio=0, weight_decay=0.0005, weight_ood=1, weight_target=1, weight_targetclass=1)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.set_printoptions(threshold=10000)\n",
    "from torch_geometric.datasets import Planetoid,Reddit2,Flickr\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch_geometric.loader import DataLoader\n",
    "from help_funcs import prune_unrelated_edge,prune_unrelated_edge_isolated, clu_prune_unrelated_edge\n",
    "import scipy.sparse as sp\n",
    "from torch_geometric.utils import subgraph\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "        default=True, help='debug mode')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--seed', type=int, default=12, help='Random seed.')\n",
    "parser.add_argument('--model', type=str, default='GCN', help='model',\n",
    "                    choices=['GCN','GAT','GraphSage','GIN'])\n",
    "parser.add_argument('--dataset', type=str, default='Pubmed', \n",
    "                    help='Dataset',\n",
    "                    choices=['Cora','Pubmed','Flickr','ogbn-arxiv','Citeseer','Reddit2'])\n",
    "parser.add_argument('--train_lr', type=float, default=0.01,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=128,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--thrd', type=float, default=0.5)\n",
    "parser.add_argument('--target_class', type=int, default=2)\n",
    "parser.add_argument('--k', type=int, default=100)\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--epochs', type=int,  default=1000, help='Number of epochs to train benign and backdoor model.')\n",
    "parser.add_argument('--rec_epochs', type=int,  default=30, help='Number of epochs to train benign and backdoor model.')\n",
    "parser.add_argument('--trojan_epochs', type=int,  default=400, help='Number of epochs to train trigger generator.')\n",
    "parser.add_argument('--inner', type=int,  default=1, help='Number of inner')\n",
    "# backdoor setting\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--trigger_size', type=int, default=3,\n",
    "                    help='tirgger_size')\n",
    "parser.add_argument('--use_vs_number', action='store_true', default=True,\n",
    "                    help=\"if use detailed number to decide Vs\")\n",
    "parser.add_argument('--vs_ratio', type=float, default=0,\n",
    "                    help=\"ratio of poisoning nodes relative to the full graph\")\n",
    "parser.add_argument('--range', type=float, default=1.0,\n",
    "                    help=\"ratio of poisoning nodes relative to the full graph\")\n",
    "parser.add_argument('--vs_number', type=int, default=160,\n",
    "                    help=\"number of poisoning nodes relative to the full graph\")\n",
    "# defense setting\n",
    "parser.add_argument('--defense_mode', type=str, default=\"none\",\n",
    "                    choices=['prune', 'isolate', 'none','reconstruct'],\n",
    "                    help=\"Mode of defense\")\n",
    "parser.add_argument('--prune_thr', type=float, default=0.8,\n",
    "                    help=\"Threshold of prunning edges\")\n",
    "parser.add_argument('--target_loss_weight', type=float, default=1,\n",
    "                    help=\"Weight of optimize outter trigger generator\")\n",
    "parser.add_argument('--weight_target', type=float, default=1,\n",
    "                    help=\"Weight of optimize outter trigger generator\")\n",
    "parser.add_argument('--weight_ood', type=float, default=1,\n",
    "                    help=\"Weight of optimize outter trigger generator\")\n",
    "parser.add_argument('--weight_targetclass', type=float, default=1,\n",
    "                    help=\"Weight of optimize outter trigger generator\")\n",
    "parser.add_argument('--outter_size', type=int, default=4096,\n",
    "                    help=\"Weight of optimize outter trigger generator\")\n",
    "parser.add_argument('--homo_loss_weight', type=float, default=100,\n",
    "                    help=\"Weight of optimize similarity loss\")\n",
    "parser.add_argument('--homo_boost_thrd', type=float, default=0.8,\n",
    "                    help=\"Threshold of increase similarity\")\n",
    "# attack setting\n",
    "parser.add_argument('--dis_weight', type=float, default=1,\n",
    "                    help=\"Weight of cluster distance\")\n",
    "parser.add_argument('--selection_method', type=str, default='none',\n",
    "                    choices=['loss','conf','cluster','none','cluster_degree'],\n",
    "                    help='Method to select idx_attach for training trojan model (none means randomly select)')\n",
    "parser.add_argument('--test_model', type=str, default='GCN',\n",
    "                    choices=['GCN','GAT','GraphSage','GIN'],\n",
    "                    help='Model used to attack')\n",
    "parser.add_argument('--evaluate_mode', type=str, default='1by1',\n",
    "                    choices=['overall','1by1'],\n",
    "                    help='Model used to attack')\n",
    "# GPU setting\n",
    "parser.add_argument('--device_id', type=int, default=2,\n",
    "                    help=\"Threshold of prunning edges\")\n",
    "# args = parser.parse_args()\n",
    "args = parser.parse_known_args()[0]\n",
    "args.cuda =  not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(('cuda:{}' if torch.cuda.is_available() else 'cpu').format(args.device_id))\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_undirected\n",
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([T.NormalizeFeatures()])\n",
    "\n",
    "if(args.dataset == 'Cora' or args.dataset == 'Citeseer' or args.dataset == 'Pubmed'):\n",
    "    dataset = Planetoid(root='./data/', \\\n",
    "                        name=args.dataset,\\\n",
    "                        transform=transform)\n",
    "elif(args.dataset == 'Flickr'):\n",
    "    dataset = Flickr(root='./data/Flickr/', \\\n",
    "                    transform=transform)\n",
    "elif(args.dataset == 'Reddit2'):\n",
    "    dataset = Reddit2(root='./data/Reddit2/', \\\n",
    "                    transform=transform)\n",
    "elif(args.dataset == 'ogbn-arxiv'):\n",
    "    from ogb.nodeproppred import PygNodePropPredDataset\n",
    "    # Download and process data at './dataset/ogbg_molhiv/'\n",
    "    dataset = PygNodePropPredDataset(name = 'ogbn-arxiv', root='./data/')\n",
    "    split_idx = dataset.get_idx_split() \n",
    "\n",
    "data = dataset[0].to(device)\n",
    "\n",
    "if(args.dataset == 'ogbn-arxiv'):\n",
    "    nNode = data.x.shape[0]\n",
    "    setattr(data,'train_mask',torch.zeros(nNode, dtype=torch.bool).to(device))\n",
    "    # dataset[0].train_mask = torch.zeros(nEdge, dtype=torch.bool).to(device)\n",
    "    data.val_mask = torch.zeros(nNode, dtype=torch.bool).to(device)\n",
    "    data.test_mask = torch.zeros(nNode, dtype=torch.bool).to(device)\n",
    "    data.y = data.y.squeeze(1)\n",
    "    \n",
    "if(args.dataset == 'Reddit2'):\n",
    "    num_nodes_to_sample = 20000  # Adjust this based on your needs\n",
    "\n",
    "    # Randomly select a subset of nodes\n",
    "    sampled_nodes = torch.randint(data.num_nodes, (num_nodes_to_sample,), device=device)\n",
    "\n",
    "    # Perform subgraph sampling\n",
    "    edge,_ = subgraph(sampled_nodes, data.edge_index)\n",
    "    data.edge_index = edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_split\n",
    "data, idx_train, idx_val, idx_clean_test, idx_atk = get_split(args,data,device)\n",
    "\n",
    "from torch_geometric.utils import to_undirected\n",
    "from utils import subgraph\n",
    "data.edge_index = to_undirected(data.edge_index)\n",
    "train_edge_index,_, edge_mask = subgraph(torch.bitwise_not(data.test_mask),data.edge_index,relabel_nodes=False)\n",
    "mask_edge_index = data.edge_index[:,torch.bitwise_not(edge_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of benign training nodes 3943\n",
      "number of poisoned target nodes 160\n"
     ]
    }
   ],
   "source": [
    "from sklearn_extra import cluster\n",
    "from models.backdoor import Backdoor\n",
    "from models.construct import model_construct\n",
    "import heuristic_selection as hs\n",
    "from torch.distributions.bernoulli import Bernoulli\n",
    "\n",
    "# select poisoned target node #\n",
    "\n",
    "# filter out the unlabeled nodes except from training nodes and testing nodes, nonzero() is to get index, flatten is to get 1-d tensor\n",
    "unlabeled_idx = (torch.bitwise_not(data.test_mask)&torch.bitwise_not(data.train_mask)).nonzero().flatten()\n",
    "if(args.use_vs_number):\n",
    "    size = args.vs_number\n",
    "else:\n",
    "    size = int((len(data.test_mask)-data.test_mask.sum())*args.vs_ratio)\n",
    "# print(\"#Attach Nodes:{}\".format(size))\n",
    "assert size>0, 'The number of selected trigger nodes must be larger than 0!'\n",
    "# here is randomly select poison nodes from unlabeled nodes\n",
    "if(args.selection_method == 'none'):\n",
    "    idx_attach = hs.obtain_attach_nodes(args,unlabeled_idx,size)\n",
    "elif(args.selection_method == 'cluster'):\n",
    "    idx_attach = hs.cluster_distance_selection(args,data,idx_train,idx_val,idx_clean_test,unlabeled_idx,train_edge_index,size,device)\n",
    "    idx_attach = torch.LongTensor(idx_attach).to(device)\n",
    "elif(args.selection_method == 'cluster_degree'):\n",
    "    if(args.dataset == 'Pubmed'):\n",
    "        idx_attach = hs.cluster_degree_selection_seperate_fixed(args,data,idx_train,idx_val,idx_clean_test,unlabeled_idx,train_edge_index,size,device)\n",
    "    else:\n",
    "        idx_attach = hs.cluster_degree_selection(args,data,idx_train,idx_val,idx_clean_test,unlabeled_idx,train_edge_index,size,device)\n",
    "    idx_attach = torch.LongTensor(idx_attach).to(device)\n",
    "# print(\"idx_attach: {}\".format(idx_attach))\n",
    "unlabeled_idx = torch.tensor(list(set(unlabeled_idx.cpu().numpy()) - set(idx_attach.cpu().numpy()))).to(device)\n",
    "print('number of benign training nodes', len(idx_train))\n",
    "print('number of poisoned target nodes', len(idx_attach))\n",
    "\n",
    "# Cora\n",
    "# idx_attach = torch.tensor([1672, 2399, 1785, 2020, 2013, 1652,  208, 1220, 2128,  446])\n",
    "# Flicker\n",
    "idx_attach = torch.tensor([ 2407, 14892, 10532, 11865, 10343,  4477,  6124, 13501, 16064, 16288,\n",
    "        13241, 19092,  3261,  1473,   773,  4570,   744, 19660,    41, 17647,\n",
    "         2590, 16881,  3837, 13691,  8013,  9920,   636,  4780, 13109, 13351,\n",
    "        10086,  4145,  8146, 11758,  3936, 18992,  5991,  8038, 18082, 16778,\n",
    "        14764, 18516, 18624,  2659, 11568,  6363, 17628,  7541, 17529,  8857,\n",
    "        15031,   387, 15655, 18300, 11006,     1, 18977,  6870,  4800,  9171,\n",
    "         2752,  3509,  9451,  5994, 10639,  8514, 13852, 15909, 15383, 18961,\n",
    "         3241, 11481, 12033, 13359,  6130,  8003,  7938,  9119, 16206,  7469,\n",
    "          512, 12784,  9765,  3562,  6826,  6278, 13067,   247,  2562, 13399,\n",
    "         7239, 14831,  8724,  8416,  4572,  7645, 12721, 16473,  7433,  9726,\n",
    "         3245, 16527, 19033,  6070, 11668,  7818, 14003, 15038,  4301,  8838,\n",
    "        18121,   823,  6874,  7616, 11089,  8844,  7886, 17175,  7113,  7481,\n",
    "         2625,   449, 10371,  1772, 15689,  4812,  7556, 12247, 17101,  9577,\n",
    "        11005,  9181,   183,  4061, 11633, 14199, 16526,  7711,  6759, 18305,\n",
    "         4873,   683, 18104,  7229, 12772, 10363, 15239,  8594, 16058,  5771,\n",
    "        13088, 15769, 15966,   885,  5873,  8670, 15267,  9813,  3823, 17756])\n",
    "\n",
    "idx_attach = idx_attach.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## trigger generator ##\n",
    "model = Backdoor(args,device)\n",
    "model.fit(data.x, train_edge_index, None, data.y, idx_train,idx_attach, unlabeled_idx, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = 'GCN'\n",
    "total_overall_asr = 0\n",
    "total_overall_ca = 0\n",
    "args.test_model = test_model\n",
    "rs = np.random.RandomState(args.seed)\n",
    "seeds = rs.randint(1000,size=1)\n",
    "overall_asr = 0\n",
    "overall_ca = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load poisoned graph #\n",
    "# poison_x = torch.load('poison_x.pt')\n",
    "# poison_edge_index = torch.load('poison_edge_index.pt')\n",
    "# poison_edge_weights = torch.load('poison_edge_weights.pt')\n",
    "# poison_labels = torch.load('poison_labels.pt')\n",
    "poison_x = torch.load('./UGBA/poison_x_pubmed.pt')\n",
    "poison_edge_index = torch.load('./UGBA/poison_edge_index_pubmed.pt')\n",
    "poison_edge_weights = torch.load('./UGBA/poison_edge_weights_pubmed.pt')\n",
    "poison_labels = torch.load('./UGBA/poison_labels_pubmed.pt')\n",
    "# poison_x = torch.load('/home/zbz5349/defense_backdoor/DPGBA/kdd-backdooor/run_arxiv/poison_x.pt')\n",
    "# poison_edge_index = torch.load('/home/zbz5349/defense_backdoor/DPGBA/kdd-backdooor/run_arxiv/poison_edge_index.pt')\n",
    "# poison_edge_weights = torch.load('/home/zbz5349/defense_backdoor/DPGBA/kdd-backdooor/run_arxiv/poison_edge_weights.pt')\n",
    "# poison_labels = torch.load('/home/zbz5349/defense_backdoor/DPGBA/kdd-backdooor/run_arxiv/poison_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=True, dataset='Pubmed', debug=True, defense_mode='none', device_id=2, dis_weight=1, dropout=0.5, epochs=1000, evaluate_mode='1by1', hidden=128, homo_boost_thrd=0.8, homo_loss_weight=100, inner=1, k=100, lr=0.01, model='GCN', no_cuda=False, outter_size=4096, prune_thr=0.8, range=1.0, rec_epochs=30, seed=12, selection_method='none', target_class=2, target_loss_weight=1, test_model='GCN', thrd=0.5, train_lr=0.01, trigger_size=3, trojan_epochs=400, use_vs_number=True, vs_number=160, vs_ratio=0, weight_decay=0.0005, weight_ood=1, weight_target=1, weight_targetclass=1)\n"
     ]
    }
   ],
   "source": [
    "print(args)\n",
    "\n",
    "mask = data.y[idx_attach] != args.target_class\n",
    "mask = mask.to(device)\n",
    "\n",
    "## only attack those has groud truth labels != target_class ##\n",
    "idx_attach = idx_attach[(data.y[idx_attach] != args.target_class).nonzero().flatten()]\n",
    "\n",
    "bkd_tn_nodes = torch.cat([idx_train,idx_attach]).to(device)\n",
    "# test_model = model_construct(args,args.test_model,data,device).to(device) \n",
    "known_nodes = torch.cat([idx_train,idx_attach]).to(device)\n",
    "predictions = []\n",
    "# edge weight for clean edge_index, may use later #\n",
    "edge_weight = torch.ones([data.edge_index.shape[1]],device=device,dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(97, device='cuda:2')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0], device='cuda:2')\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2], device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "print(data.y[idx_attach])\n",
    "# idx_attach is selected target node #\n",
    "print(poison_labels[idx_attach])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on poisoned target nodes: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_model = model_construct(args,args.test_model,data,device).to(device) \n",
    "test_model.fit(poison_x,poison_edge_index, poison_edge_weights, poison_labels, bkd_tn_nodes, idx_val,train_iters=args.epochs,verbose=False)\n",
    "test_model.eval()\n",
    "clean_acc = test_model.test(poison_x,poison_edge_index, poison_edge_weights,poison_labels,idx_attach)\n",
    "output_clean, x = test_model(poison_x,poison_edge_index,poison_edge_weights)\n",
    "ori_predict = torch.exp(output_clean[known_nodes])\n",
    "print(\"accuracy on poisoned target nodes: {:.4f}\".format(clean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2], device='cuda:2')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_clean[idx_attach].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR: 1.0000\n",
      "Flip ASR: 1.0000/1198 nodes\n",
      "CA: 0.8453\n"
     ]
    }
   ],
   "source": [
    "# test backdoored model for comparison #\n",
    "induct_edge_index = torch.cat([poison_edge_index,mask_edge_index],dim=1)\n",
    "induct_edge_weights = torch.cat([poison_edge_weights,torch.ones([mask_edge_index.shape[1]],dtype=torch.float,device=device)])\n",
    "induct_x, induct_edge_index,induct_edge_weights = model.inject_trigger(idx_atk,poison_x,induct_edge_index,induct_edge_weights,device)\n",
    "induct_x, induct_edge_index,induct_edge_weights = induct_x.clone().detach(), induct_edge_index.clone().detach(),induct_edge_weights.clone().detach()\n",
    "\n",
    "output, x = test_model(induct_x,induct_edge_index,induct_edge_weights)\n",
    "train_attach_rate = (output.argmax(dim=1)[idx_atk]==args.target_class).float().mean()\n",
    "print(\"ASR: {:.4f}\".format(train_attach_rate))\n",
    "asr = train_attach_rate\n",
    "flip_idx_atk = idx_atk[(data.y[idx_atk] != args.target_class).nonzero().flatten()]\n",
    "flip_asr = (output.argmax(dim=1)[flip_idx_atk]==args.target_class).float().mean()\n",
    "print(\"Flip ASR: {:.4f}/{} nodes\".format(flip_asr,flip_idx_atk.shape[0]))\n",
    "ca = test_model.test(induct_x,induct_edge_index,induct_edge_weights,data.y,idx_clean_test)\n",
    "print(\"CA: {:.4f}\".format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge drop #\n",
    "def sample_noise_all(edge_index, edge_weight,device):\n",
    "    noisy_edge_index = edge_index.clone().detach()\n",
    "    if(edge_weight == None):\n",
    "        noisy_edge_weight = torch.ones([noisy_edge_index.shape[1],]).to(device)\n",
    "    else:\n",
    "        noisy_edge_weight = edge_weight.clone().detach()\n",
    "    # # rand_noise_data = copy.deepcopy(data)\n",
    "    # rand_noise_data.edge_weight = torch.ones([rand_noise_data.edge_index.shape[1],]).to(device)\n",
    "    m = Bernoulli(torch.tensor([0.5]).to(device))\n",
    "    mask = m.sample(noisy_edge_weight.shape).squeeze(-1).int()\n",
    "    # print('mask',mask)\n",
    "    rand_inputs = torch.randint_like(noisy_edge_weight, low=0, high=2).squeeze().int().to(device)\n",
    "    # print(rand_noise_data.edge_weight.shape,mask.shape)\n",
    "    noisy_edge_weight = noisy_edge_weight * mask #+ rand_inputs * (1-mask)\n",
    "        \n",
    "    if(noisy_edge_weight!=None):\n",
    "        noisy_edge_index = noisy_edge_index[:,noisy_edge_weight.nonzero().flatten().long()]\n",
    "        noisy_edge_weight = torch.ones([noisy_edge_index.shape[1],]).to(device)\n",
    "    return noisy_edge_index, noisy_edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test robustness #\n",
    "for i in range(20):\n",
    "            test_model.eval()\n",
    "            noisy_poison_edge_index, noisy_poison_edge_weights = sample_noise_all(poison_edge_index, poison_edge_weights, device)\n",
    "            output, x = test_model(poison_x,noisy_poison_edge_index,noisy_poison_edge_weights)\n",
    "            train_attach_rate = (output.argmax(dim=1)[idx_attach]==args.target_class).float().mean()\n",
    "            train_clean_rate = (output.argmax(dim=1)[idx_train]==data.y[idx_train]).float().mean()\n",
    "            predictions.append(torch.exp(output[known_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.argmax(predictions[8][23868])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_of_less_robust tensor([3946, 3996, 3977, 3963, 4017, 4032, 3990, 4004, 3975, 4020, 3968, 3986,\n",
      "        4019, 4031, 3999, 4021, 4024, 3951, 3970, 1214, 3974, 3956, 3960, 4000,\n",
      "        3979, 3989, 3944, 4001, 3988, 4016, 4029, 4003, 4030, 3966, 3978, 4009,\n",
      "        4023, 3972, 3959, 3954, 3982, 3980, 3998, 3971, 4010, 4002, 3947, 3949,\n",
      "        3985, 4036, 4008, 3967, 3965, 3973, 4034, 4012, 3993, 4013, 3955, 3953,\n",
      "        4022, 3948, 3962, 3964,  521, 4027, 3994, 3961, 4039, 4038,  307, 3943,\n",
      "        3945, 4018, 1690, 3992, 4037,  511, 4014, 3981, 2770, 3952, 4033, 4006,\n",
      "          25, 2067, 2368, 3950, 4005, 3983, 3997,  499, 1763, 4011, 3858, 4025,\n",
      "        4026], device='cuda:2')\n",
      "count 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zbz5349/anaconda3/envs/spurious/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-8\n",
    "deviations = []\n",
    "for sub_pred in predictions:\n",
    "    sub_pred += epsilon\n",
    "    deviation = F.kl_div(sub_pred.log(), ori_predict, reduce=False)\n",
    "    deviations.append(deviation)\n",
    "\n",
    "summed_deviations = torch.zeros_like(deviations[0]).to(deviations[0].device)\n",
    "for deviation in deviations:\n",
    "    ##### summed deviations for each node #####\n",
    "    summed_deviations += deviation\n",
    "\n",
    "\n",
    "##### get the index for nodes with less robustness #####\n",
    "    \n",
    "##### args.vs_number is unknown #####\n",
    "index_of_less_robust = torch.sort(torch.mean(summed_deviations,dim=-1),descending=True)[1][:mask.sum()]\n",
    "print('index_of_less_robust',index_of_less_robust)\n",
    "\n",
    "##### count how many poisoned target nodes are selected in less robustness nodes #####\n",
    "count = 0\n",
    "dd = []\n",
    "for idx in index_of_less_robust:\n",
    "    if idx >= len(known_nodes)-args.vs_number:\n",
    "        count += 1\n",
    "        dd.append(idx)\n",
    "print('count',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([47.8962, 43.1829, 43.0248, 42.2769, 40.3703, 39.0910, 38.7749, 38.6140,\n",
       "        37.6082, 37.3875, 37.2452, 33.9707, 31.8237, 30.5774, 30.4698, 30.2592,\n",
       "        29.5784, 29.2813, 29.1798, 28.8391, 28.3742, 27.8984, 26.5705, 25.8827,\n",
       "        25.6239, 25.4637, 23.9391, 23.1581, 23.0624, 22.8996, 22.5237, 22.4997,\n",
       "        22.4461, 22.2405, 21.9804, 21.9786, 21.4537, 21.2805, 21.2725, 20.5033,\n",
       "        20.4271, 20.3409, 20.0834, 19.3304, 19.1143, 18.3990, 18.0732, 17.6925,\n",
       "        17.6218, 16.9937, 16.0759, 15.0894, 14.5731, 14.4302, 14.0197, 13.6628,\n",
       "        13.2050, 13.2000, 12.6854, 12.6307, 11.4814, 11.4274, 10.9080, 10.7808,\n",
       "        10.6076, 10.5449, 10.5199, 10.2463, 10.2008, 10.1651, 10.0652,  9.7857,\n",
       "         9.5664,  9.3368,  9.1798,  9.0735,  8.8885,  8.8655,  8.6817,  8.6690,\n",
       "         8.6104,  8.2618,  7.8158,  7.7959,  7.6472,  7.5634,  7.5572,  7.5259,\n",
       "         6.8803,  6.8215,  6.7785,  6.7647,  6.5377,  6.3901,  6.3485,  6.3240,\n",
       "         6.2470], device='cuda:2', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(torch.mean(summed_deviations,dim=-1),descending=True)[0][:mask.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(97, device='cuda:2')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ori_predict))\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# visualize robustness distribution #\n",
    "a=torch.mean(summed_deviations,dim=-1)\n",
    "a_excluding_last_40 = a[:-args.vs_number].detach().cpu()\n",
    "a_last=a[-mask.sum():].detach().cpu()\n",
    "\n",
    "\n",
    "a_last_40 = a[-args.vs_number:].detach().cpu()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "indices_to_remove = [i for i, node in enumerate(known_nodes[-args.vs_number:]) if data.y[node] == args.target_class]\n",
    "\n",
    "indices_to_remove = []\n",
    "\n",
    "a_last_list = list(a_last)\n",
    "\n",
    "indices_to_check = range(len(known_nodes[-args.vs_number:]))\n",
    "\n",
    "# indices_to_remove = []\n",
    "\n",
    "# ##### find those nodes that are already have target class or poisoned failed #####\n",
    "# for i in indices_to_check:\n",
    "#     condition1 = data.y[known_nodes[-args.vs_number:][i]] == args.target_class\n",
    "#     condition2 = output.argmax(dim=1)[idx_attach[i]] != args.target_class\n",
    "    \n",
    "#     if condition1 or condition2:\n",
    "#         indices_to_remove.append(i)\n",
    "\n",
    "# for index in sorted(indices_to_remove, reverse=True):\n",
    "#     del a_last_list[index]\n",
    "\n",
    "\n",
    "a_last_40 = a_last_list\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.figure(figsize=(40, 24))\n",
    "##### benign nodes #####\n",
    "plt.hist(a_excluding_last_40, bins=20, alpha=0.5, label='benign nodes', density=True)\n",
    "##### poisoned success nodes #####\n",
    "plt.hist(a_last_40, bins=20, alpha=0.5, label='poisoned target nodes',density=True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of robustness for each node')\n",
    "plt.savefig('a.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_clean[idx_attach].argmax(dim=1)\n",
    "output_clean = torch.exp(output_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2], device='cuda:2')\n",
      "[0.0003375572559889406, 3.14079225063324e-05, 0.00014035403728485107, 0.0052675469778478146, 0.0004398748278617859, 0.0009955255081877112, 0.0016699049156159163, 0.0009458474814891815, 0.0014372393488883972, 0.0011128647020086646, 0.003506205976009369, 0.00796530582010746, 0.0055937133729457855, 0.001437778351828456, 0.0013884585350751877, 0.001876838505268097, 0.00026164454175159335, 0.0019642352126538754, 0.0018627243116497993, 0.0025472473353147507, 0.0029625201132148504, 0.003079160815104842, 0.0016943620285019279, 0.002394114388152957, 0.0023073290940374136, 0.04716971516609192, 0.01135165523737669, 1.973162170543219e-06, 0.006672114133834839, 0.015423203818500042, 0.00032485401607118547, 0.00013877576566301286, 0.009005775675177574, 0.003501353319734335, 0.0011113410582765937, 0.0010097710182890296, 0.0027612075209617615, 0.00883572082966566, 0.0029439318459481, 0.007188643328845501, 0.00032700476003810763, 0.005087519995868206, 0.017751451581716537, 0.00013192743062973022, 0.0005985039169900119, 2.6984762371284887e-05, 0.05944450944662094, 0.010024234652519226, 0.0005488644237630069, 0.04351023584604263, 0.0001600061950739473, 0.00011242678010603413, 0.0003350724873598665, 0.003958342131227255, 0.0028823267202824354, 0.006444843020290136, 0.005515966098755598, 0.0027571420650929213, 0.0019093155860900879, 0.0018878281116485596, 0.0018885508179664612, 0.001429407624527812, 0.0018051385413855314, 0.0014493981143459678, 0.0007084285607561469, 0.0014521268894895911, 0.0007930429419502616, 0.0014308288227766752, 0.0019236467778682709, 0.0021012327633798122, 0.0005167530616745353, 0.001037518261000514, 0.001853129593655467, 0.000993217690847814, 0.01595868170261383, 0.03761085495352745, 0.01048105489462614, 6.0741713241441175e-05, 4.922521111438982e-05, 0.00014879570517223328, 7.7222168215485e-08, 1.4003211390445358e-06, 1.5159137547016144e-05, 0.00011746794916689396, 0.0017259170999750495, 0.09543657302856445, 0.04624851047992706, 0.011893751099705696, 0.00014412961900234222, 0.0013963577803224325, 0.01771436631679535, 0.0015316655626520514, 0.0021368018351495266, 0.0011167488992214203, 0.0017265044152736664, 0.0020209222566336393, 0.0013308189809322357, 0.011876314878463745, 0.0022773544769734144, 0.0021164182107895613, 0.002294667763635516, 0.0021331775933504105, 0.03583022579550743, 0.014427796006202698, 0.030067872256040573, 0.0014442838728427887, 8.905989670893177e-05, 0.04212063178420067, 0.00020158695406280458, 0.0002733722794800997, 0.00048541295109316707, 0.0003724205307662487, 0.00037327231257222593, 6.545878477481892e-06, 0.00016870505351107568, 0.00013486544776242226, 0.00033739954233169556, 0.0005520149134099483, 0.00033295550383627415, 0.00020980618137400597, 0.0003671674057841301, 0.0003218180499970913, 0.0002403374237474054, 0.00037404545582830906, 0.0004977569333277643, 0.0002762571384664625, 0.0002889741153921932, 0.0002989565837197006, 0.00016530719585716724, 0.0002846788556780666, 0.0003802857827395201, 0.8452873229980469, 0.007920949719846249, 0.0887475460767746, 0.0006808614125475287, 0.001379994093440473, 0.009489640593528748, 0.00027546536875888705, 0.0002058073878288269, 0.000833685218822211, 0.004056519828736782, 0.004278404172509909, 4.631529373000376e-05, 0.00014402717351913452, 3.4265220165252686e-05, 0.0031892559491097927, 0.0065939477644860744, 0.025424635037779808, 0.017799189314246178, 0.0063880858942866325, 0.011698096990585327, 0.008947080001235008, 0.007110933773219585, 0.0019493898143991828, 0.00912520568817854, 0.013120274059474468, 0.0021649114787578583, 0.0010362789034843445, 0.004509091377258301, 0.0002254511637147516, 0.002024711575359106, 0.0030412774067372084, 0.001172588556073606, 0.004406226333230734, 0.009574085474014282, 0.011715668253600597, 0.0008504875004291534, 0.003890346735715866, 0.01915142498910427, 0.0018202252686023712, 0.01104792021214962, 0.0016555053880438209, 0.0029321364127099514, 0.02845669351518154, 0.03534041345119476, 0.000557897612452507, 0.00037534753209911287, 7.184160494944081e-05, 0.00025841471506282687, 0.003468173323199153, 0.0008755940943956375, 0.0008686287328600883, 0.0014442622195929289, 0.000490769452881068, 0.00021812475461047143, 0.0006991479313001037, 0.00010530806321185082, 0.0008830096339806914, 0.0015759698580950499, 0.0005532832583412528, 0.0507669523358345, 0.0002260829060105607, 0.0004926262190565467, 0.00033908835030160844, 0.001926568103954196, 0.009816944599151611, 0.08671317994594574, 0.017219139263033867, 0.1285494714975357, 0.00013688206672668457, 0.004438964184373617, 0.0005494995857588947, 0.0001841516641434282, 0.0035229537170380354, 0.0015439571579918265, 3.971780643041711e-06, 0.002046257257461548, 0.012362468056380749, 0.06893835961818695, 0.008370107039809227, 0.005319739691913128, 0.002800112124532461, 0.005065766628831625, 0.03158973529934883, 0.012060848996043205, 0.0018194864969700575, 0.0037483673077076674, 0.0025922581553459167, 0.0031474034767597914, 0.0063416436314582825, 0.0004963725805282593, 0.012266352772712708, 0.002874041674658656, 0.0010309964418411255, 0.39428645372390747, 0.025042738765478134, 0.0025768927298486233, 0.018247123807668686, 0.0003887477214448154, 0.001986425369977951, 7.233272299345117e-06, 0.005763049237430096, 0.02529364824295044, 0.00011134396481793374, 0.010477746836841106, 0.003880530595779419, 0.00366220879368484, 0.002804212272167206, 0.004964575171470642, 0.002462349832057953, 0.002748283324763179, 0.004845199640840292, 0.015041433274745941, 8.638513827463612e-05, 0.00016892142593860626, 0.000569172843825072, 0.003294175025075674, 0.0949375256896019, 0.09301000833511353, 5.107329343445599e-06, 1.1489222373484154e-07, 1.0480289347469807e-07, 2.6729929913926753e-07, 3.733730409294367e-07, 4.018827894469723e-05, 1.0920727788743534e-07, 1.0623868547554594e-05, 1.7869073190013296e-06, 4.339478323345247e-07, 7.021978376542393e-07, 5.160885621080524e-07, 3.613148464864935e-06, 1.1459595043561421e-05, 2.3573279577249195e-06, 3.421640570877571e-08, 2.5081731109821703e-06, 0.005842546932399273, 0.006940255872905254, 0.001256374642252922, 0.0009066542843356729, 0.0012907256605103612, 0.0012891588266938925, 0.000886362511664629, 0.0010934645542874932, 0.00046118046157062054, 0.0007924862438812852, 0.0007266447646543384, 0.0008211792446672916, 0.0011258175363764167, 0.0007732618832960725, 0.0009079470182769, 0.0012037516571581364, 0.0010892925783991814, 0.0011059856042265892, 0.0008903585840016603, 0.0009798003593459725, 0.0007114897016435862, 0.0012966364156454802, 0.0011878997320309281, 0.004039580933749676, 0.002842262387275696, 0.0017630060901865363, 0.0004123167018406093, 0.0011761540081351995, 0.0017362283542752266, 0.0003642762894742191, 0.001716994447633624, 0.0010812627151608467, 0.0004351884126663208, 0.0008092783391475677, 0.0010264904703944921, 0.00032699978328309953, 0.15798304975032806, 0.0008740996709093451, 0.0006756882066838443, 0.017938120290637016, 0.0013761818408966064, 0.0012560015311464667, 0.12091435492038727, 5.6234448493341915e-06, 2.528709501348203e-06, 5.713132850360125e-06, 9.354682333650999e-06, 1.8765711502055638e-05, 7.5275092967785895e-06, 8.669611816003453e-06, 6.635367753915489e-06, 7.596099749207497e-06, 6.258318080654135e-06, 2.918522568506887e-06, 5.740769665862899e-06, 2.675825726328185e-06, 7.571560672658961e-06, 7.342421213252237e-06, 1.9365943444427103e-06, 9.041296834766399e-06, 8.302238711621612e-06, 5.653455446008593e-06, 4.3134132283739746e-06, 4.4831349441665225e-06, 1.363834599032998e-06, 6.435383511416148e-06, 7.290374014701229e-06, 6.6566572058945894e-06, 8.173294190783054e-06, 8.4441253420664e-06, 3.7458448787219822e-06, 5.609118488791864e-06, 8.558061381336302e-06, 8.875575076672249e-06, 7.310067303478718e-06, 7.782444299664348e-06, 5.085234988655429e-06, 6.6287639128859155e-06, 5.981669346510898e-06, 7.475660822819918e-06, 6.287019459705334e-06, 5.168161351321032e-06, 3.0896044336259365e-05, 8.332352081197314e-06, 8.177921699825674e-06, 8.466951840091497e-06, 3.533704784786096e-06, 7.035703220026335e-06, 7.603327503602486e-06, 2.7509704523254186e-06, 4.9742229748517275e-06, 4.731858552986523e-06, 5.014335329178721e-06, 7.5176844802626874e-06, 8.238424015871715e-06, 2.363831299589947e-06, 0.16468475759029388, 0.020826175808906555, 0.00488387793302536, 0.001930552301928401, 0.0027092844247817993, 0.004447107668966055, 0.0018990486860275269, 0.0029359832406044006, 0.030044924467802048, 0.010251887142658234, 0.01557090412825346, 0.0007824985077604651, 0.0003344242868479341, 0.00019681453704833984, 0.0009971149265766144, 0.3058874309062958, 0.036510270088911057, 0.0019245899748057127, 0.003063549753278494, 0.00045594945549964905, 0.0015818167012184858, 0.0005037753726355731, 0.001014903886243701, 0.016794469207525253, 0.00037710307515226305, 0.0012794740032404661, 0.005350057035684586, 0.0023810975253582, 0.009281855076551437, 0.011145289056003094, 0.005386382341384888, 0.004903356544673443, 0.0006164952064864337, 0.0010917950421571732, 0.0016235820949077606, 0.0005946165765635669, 0.0005276917363516986, 9.274296462535858e-05, 0.0009519855375401676, 0.0008083700085990131, 0.0007206543232314289, 0.0018648518016561866, 0.0008290546829812229, 0.0006220763316377997, 0.000595891266129911, 8.269989848486148e-06, 3.6332447052700445e-05, 1.6069312550825998e-05, 3.95247116102837e-05, 0.00011151393118780106, 0.0006407536566257477, 0.0019710685592144728, 0.004550380166620016, 0.0019944510422647, 0.0022675693035125732, 0.031830161809921265, 0.0018671900033950806, 0.001958062406629324, 0.004584181122481823, 0.45397529006004333, 0.007498142775148153, 0.02712632343173027, 0.001980528235435486, 0.009131960570812225, 0.005630414001643658, 0.006477519869804382, 4.2549025238258764e-05, 0.0011299442267045379, 0.00025710463523864746, 0.03930558264255524, 0.0012266449630260468, 5.147358024260029e-05, 0.005353820975869894, 0.0002123707381542772, 0.00025640492094680667, 0.002983370330184698, 0.0009336099028587341, 0.00030013424111530185, 0.01738925836980343, 0.0015225758543238044, 0.002425695536658168, 0.021673373878002167, 0.010568353347480297, 0.005384269170463085, 0.23549330234527588, 0.005566011182963848, 0.008783127181231976, 0.0004247725009918213, 0.020731236785650253, 0.007190982811152935, 0.005916088819503784, 0.00010672211647033691, 0.001423930749297142, 0.000868380069732666, 0.000922083854675293, 0.010048206895589828, 0.0032942357938736677, 0.0003881466982420534, 0.04965854808688164, 0.003523975145071745, 0.07781189680099487, 0.1181253045797348, 0.0028144842945039272, 0.004896844737231731, 0.003210879862308502, 0.0022662929259240627, 0.0016226371517404914, 0.0020788933616131544, 0.00903724879026413, 0.10888790339231491, 0.008705477230250835, 0.018871277570724487, 0.004014169331640005, 0.000336979835992679, 0.01109316200017929, 0.006077483296394348, 0.009969423525035381, 0.0024678311310708523, 0.017675762996077538, 0.0016818344593048096, 0.0030096869450062513, 0.0012458860874176025, 0.012067924253642559, 0.013045619241893291, 0.009267836809158325, 0.1626230776309967, 0.013558171689510345, 0.040045447647571564, 0.025060251355171204, 0.00030410662293434143, 0.0003792140632867813, 0.00017041651881299913, 0.0006689348956570029, 0.000458316266303882, 0.0008641568711027503, 0.0009034226532094181, 0.00032206004834733903, 0.0005509071052074432, 0.0012773554772138596, 0.0008570521022193134, 0.002554347738623619, 0.0002305302768945694, 0.0006434768438339233, 0.0005620146985165775, 0.00016292184591293335, 0.000250181183218956, 2.800549191306345e-05, 0.00042836740612983704, 0.00026386789977550507, 0.017934104427695274, 0.02927914634346962, 0.0989408940076828, 0.003921343944966793, 0.0002541939611546695, 0.021438507363200188, 0.0016096855979412794, 0.05660196393728256, 0.15517204999923706, 0.10997682064771652, 0.07214256376028061, 0.0020605388563126326, 0.006174619309604168, 0.0015076672425493598, 0.0010092004667967558, 0.0016666434239596128, 0.0010524317622184753, 0.0020443457178771496, 0.002207896439358592, 0.0007902762736193836, 0.0003052235988434404, 0.0013071883004158735, 0.0012037053238600492, 0.0013473983854055405, 0.0015791244804859161, 0.0002195859997300431, 0.0028981990180909634, 0.00030747056007385254, 0.02505088970065117, 0.00396651541814208, 0.07044804096221924, 0.00039276271127164364, 0.0006392033537849784, 0.0007310050423257053, 0.0011006768327206373, 0.0005837364587932825, 0.0004510178114287555, 0.0005583892925642431, 0.0005679306341335177, 0.0006525072967633605, 0.0006523555493913591, 0.0009958971058949828, 0.0007627207669429481, 0.0005302121862769127, 0.0009758942760527134, 0.0008311571436934173, 0.001105066272430122, 0.0014738594181835651, 0.0013091026339679956, 0.0013627060689032078, 0.001156594487838447, 0.0015623013023287058, 0.0017143762670457363, 0.0010726540349423885, 0.001269738539122045, 0.0012688356218859553, 0.0008311764104291797, 0.0012196673778817058, 0.001375702559016645, 0.0010513239540159702, 0.0010381669271737337, 0.0026110392063856125, 0.0009619832853786647, 0.0027908484917134047, 0.00031053958809934556, 0.00021535344421863556, 0.0037781584542244673, 0.002572012599557638, 0.0027852128259837627, 0.002379582729190588, 0.0038289863150566816, 0.007448092103004456, 0.0057702334597706795, 0.0015743182739242911, 0.007797807455062866, 0.021319735795259476, 0.005208591930568218, 0.053184881806373596, 1.895284185593482e-05, 1.860000702436082e-05, 3.591106360545382e-05, 2.5934987206710503e-05, 1.7774040315998718e-05, 2.1603365894407034e-05, 3.5542354453355074e-05, 1.740087100188248e-05, 3.824939994956367e-05, 3.0637020245194435e-05, 3.2630654459353536e-05, 3.8170685002114624e-05, 2.7728403438231908e-05, 6.42370869172737e-05, 1.496092136221705e-05, 6.457577455876162e-06, 9.666167170507833e-05, 5.231413524597883e-06, 4.3222489694016986e-06, 7.530984930781415e-06, 2.3534852516604587e-05, 0.0001995234633795917, 1.764481930877082e-05, 1.0401476174592972e-05, 5.163485184311867e-06, 0.001390760182403028, 0.012672824785113335, 0.0019880011677742004, 0.08828593790531158, 0.0031699712853878736, 0.032053567469120026, 0.000645030289888382, 0.0018128815572708845, 0.0005896383663639426, 0.0009688455611467361, 0.000452650710940361, 0.0004884458030574024, 0.00031136241159401834, 0.002823007060214877, 0.0018691237783059478, 0.0005850879242643714, 0.0009662415832281113, 0.00019244074064772576, 0.0008906055008992553, 0.0007185991853475571, 0.0008454391499981284, 0.00013928224507253617, 0.0001939241774380207, 0.0025809488724917173, 0.0016624806448817253, 0.001773939235135913, 0.0029611042700707912, 0.0009904224425554276, 0.00024138732987921685, 0.00021692723385058343, 0.001733369193971157, 0.05365464836359024, 0.0016596106579527259, 8.187567436834797e-05, 0.031877972185611725, 0.00040963044739328325, 0.0004022146458737552, 0.004975646734237671, 0.000535331666469574, 0.0009289036388508976, 0.002710620639845729, 0.021329626441001892, 0.002870639320462942, 0.00011429935693740845, 0.007190041244029999, 0.0012142136693000793, 0.05437513440847397, 0.15605990588665009, 0.033776942640542984, 0.0017830997239798307, 0.0016402493929490447, 0.0008507728343829513, 0.0010667850729078054, 0.0012781480327248573, 0.00046594752348028123, 0.001017085975036025, 0.0002063227293547243, 0.000375090487068519, 0.0008343883673660457, 0.0008757133036851883, 0.0010192515328526497, 0.0014037378132343292, 0.058763593435287476, 0.0009027744526974857, 0.0014976536622270942, 0.006525847129523754, 0.001381687237881124, 0.0008278461173176765, 0.0010754754766821861, 0.0009024410392157733, 0.0004098033532500267, 0.0015765668358653784, 0.0005201517487876117, 8.852159226080403e-05, 0.000628102570772171, 0.0006747333100065589, 0.0006705591222271323, 0.0003312875924166292, 0.02142976224422455, 0.02214047871530056, 0.029695263132452965, 0.03380881994962692, 0.017873939126729965, 0.02691934071481228, 0.000993196270428598, 0.0014022467657923698, 0.0024653549771755934, 0.00019460669136606157, 0.001039806753396988, 0.0007592166657559574, 0.00032683712197467685, 0.021932348608970642, 0.0012817507376894355, 0.0016409903764724731, 4.6510249376297e-05, 0.002187289297580719, 0.006972655653953552, 0.0005436601932160556, 0.005416497588157654, 0.0010194405913352966, 0.000231480851653032, 0.004168556537479162, 0.005320447497069836, 0.00527558010071516, 0.007387779653072357, 0.002941615879535675, 0.08344726264476776, 0.013079771772027016, 0.006414664443582296, 0.00105767953209579, 0.0010587995639070868, 0.0002639169688336551, 0.00017343214130960405, 2.673516792128794e-05, 0.006371429190039635, 0.0005234020645730197, 0.00015072152018547058, 0.0009633737499825656, 0.0006040520966053009, 0.001682595699094236, 0.0020404185634106398, 0.003493125317618251, 4.559507215162739e-05, 0.03482576832175255, 5.610321295534959e-06, 4.988202704225841e-07, 2.0947967982465343e-07, 7.816221909706655e-07, 1.864032469711674e-06, 1.4821756622040994e-06, 1.6222815020228154e-06, 2.918832933573867e-06, 1.5983048342604889e-06, 1.5699964706072933e-06, 4.267084932507714e-06, 2.6508885184739484e-06, 1.2484614671848249e-05, 9.194895028485917e-06, 1.3490692936102278e-06, 1.710737524263095e-05, 5.777013711849577e-07, 8.597562555223703e-07, 1.2024150919387466e-06, 0.0008876671781763434, 0.0005207521608099341, 0.0006840887363068759, 0.0017735952278599143, 0.006422390695661306, 0.0025628507137298584, 0.0005297847092151642, 0.0065888911485672, 0.0009207464754581451, 0.0035539008677005768, 0.02310021221637726, 0.0033347855787724257, 0.0014079747488722205, 0.0015061249723657966, 0.0013421674957498908, 0.14709840714931488, 0.07422113418579102, 0.13199907541275024, 0.0010692080250009894, 2.995257636939641e-05, 0.0001755108532961458, 0.0002570822834968567, 0.003971288911998272, 0.03764686733484268, 0.021051213145256042, 0.0005322446813806891, 0.00045393407344818115, 0.0030905157327651978, 0.003362248418852687, 0.0004200885887257755, 0.010973840951919556, 9.39766614465043e-05, 1.8949232980958186e-05, 7.674144580960274e-05, 6.128211680334061e-05, 3.644661046564579e-05, 3.2159266993403435e-05, 0.00010717951226979494, 2.4576827399869217e-06, 2.662216684257146e-05, 0.00011563363659661263, 9.485935879638419e-05, 5.18440137966536e-05, 4.834961146116257e-05, 7.925128738861531e-05, 7.000907498877496e-05, 0.22562208771705627, 1.857026290963404e-05, 0.0013764237519353628, 3.237587952753529e-05, 0.006216615438461304, 0.001739799976348877, 0.056039124727249146, 0.08251415938138962, 0.007712667342275381, 0.00794350914657116, 0.025092264637351036, 0.008905110880732536, 0.00999265443533659, 0.004217013716697693, 0.008561825379729271, 0.00036584836198017, 0.012410445138812065, 0.008265666663646698, 0.0079050213098526, 0.005125766154378653, 0.043670654296875, 0.006444571074098349, 0.002571260090917349, 0.0032437294721603394, 0.0010911941062659025, 0.0004230508056934923, 0.002486536977812648, 0.004519566893577576, 0.007695416919887066, 3.492025280138478e-05, 0.033399730920791626, 0.0012166997184976935, 0.0032069049775600433, 0.0014780325582250953, 0.006276953034102917, 0.01856725662946701, 0.0032866261899471283, 0.004839576315134764, 0.005462120287120342, 0.0029591615311801434, 0.007519137114286423, 0.004448199179023504, 0.009873703122138977, 0.010016153566539288, 0.004706816282123327, 0.006137275602668524, 0.003379425033926964, 0.00601041316986084, 0.008483554236590862, 0.0024114656262099743, 0.23698624968528748, 0.02895299158990383, 0.0065186223946511745, 0.007948133163154125, 0.0053048222325742245, 0.010058814659714699, 0.008329765871167183, 0.008088277652859688, 0.0032170279882848263, 0.015173858031630516, 0.003389606950804591, 0.008871125057339668, 0.00012194675946375355, 0.0002546105533838272, 7.457038009306416e-05, 5.201933527132496e-05, 5.135933679412119e-05, 0.008171649649739265, 0.02132401242852211, 0.005151510238647461, 0.0031245104037225246, 0.014885833486914635, 0.04685632884502411, 0.0007529035210609436, 0.003572138724848628, 3.141661727568135e-05, 0.024205941706895828, 0.006392344832420349, 0.024105532094836235, 0.021968945860862732, 0.023059062659740448, 0.017165374010801315, 0.005256150849163532, 0.005054491572082043, 0.00505482405424118, 0.004935996141284704, 0.003758107777684927, 0.004433175083249807, 0.002804623683914542, 0.008284727111458778, 0.005232859402894974, 0.02864738367497921, 0.0018081516027450562, 0.0007407417288050056, 0.004596962593495846, 0.005402890499681234, 0.0034361444413661957, 0.0039036828093230724, 0.0033137935679405928, 0.004327506758272648, 0.00388411246240139, 0.03218050301074982, 0.004162271972745657, 0.0015296190977096558, 0.000982046127319336, 0.00042880576802417636, 0.001184128224849701, 0.015634283423423767, 0.011548742651939392, 0.005985046736896038, 0.0012845546007156372, 0.0027185827493667603, 0.0009206384420394897, 0.0013892899733036757, 0.0038100332021713257, 0.00169319414999336, 0.00046435496187768877, 0.002849420066922903, 0.002197394846007228, 0.0028348814230412245, 0.003207097528502345, 0.000342274724971503, 0.0008834898471832275, 0.006750961299985647, 0.008778548799455166, 0.007187593728303909, 0.0066883317194879055, 0.005389537662267685, 0.005483299493789673, 0.006523183546960354, 0.007262767758220434, 0.007805362343788147, 0.005241956561803818, 0.00871358998119831, 0.005497653968632221, 0.005224573891609907, 0.004615139216184616, 0.0014796145260334015, 0.0019061823841184378, 9.118641901295632e-05, 0.0010373815894126892, 4.8434361815452576e-05, 0.0004161400720477104, 0.0012514725094661117, 0.00047251791693270206, 0.00034593488089740276, 0.00022459565661847591, 0.000209323363378644, 0.00020359535119496286, 0.0003337994567118585, 0.0004426426603458822, 0.00020072772167623043, 0.00016855946159921587, 0.005513550713658333, 0.005397725850343704, 0.004178185015916824, 0.002753760665655136, 0.0056307073682546616, 0.005959102418273687, 0.007285071536898613, 0.004207540303468704, 0.0037528998218476772, 0.0039554741233587265, 0.006231979932636023, 0.0005820021033287048, 0.0002230083046015352, 0.001034339307807386, 0.0008109025657176971, 0.0026245564222335815, 0.0006103751948103309, 0.00010693042713683099, 1.7676502466201782e-05, 0.0004192435590084642, 5.1585957407951355e-05, 0.10541337728500366, 1.7706461221678182e-05, 0.00022268644534051418, 0.000526486779563129, 0.0001338507718173787, 3.844810180453351e-06, 0.00010737621778389439, 0.00017979121184907854, 0.00039987158379517496, 0.00011617535346886143, 0.0002610346709843725, 0.00021114604896865785, 9.113302076002583e-05, 0.00023401761427521706, 0.000255143124377355, 0.00019457051530480385, 0.00020195823162794113, 0.0021593845449388027, 0.00916844792664051, 0.004137189593166113, 0.00952940247952938, 0.004483354743570089, 0.012151236645877361, 0.01770838163793087, 0.0043861148878932, 0.0024865109007805586, 0.003193418262526393, 0.011550615541636944, 0.001127593219280243, 0.010489106178283691, 0.026439081877470016, 0.0007440149784088135, 0.003288350999355316, 0.00035793831921182573, 0.005397190805524588, 0.0010158134391531348, 0.0005878942902199924, 0.0016369856894016266, 0.06973324716091156, 0.0007669913466088474, 0.00011962155986111611, 0.00041556856012903154, 0.00040242698742076755, 0.0004154158232267946, 3.885974729200825e-05, 0.010990560054779053, 0.014840466901659966, 0.006988149136304855, 0.00506085529923439, 0.01281379908323288, 0.0006297355284914374, 0.005242206156253815, 0.005419475492089987, 0.01104554533958435, 0.0015015329699963331, 0.04116341471672058, 0.011839285492897034, 6.880114960949868e-05, 0.0005115941166877747, 0.0008255988359451294, 0.0025427553337067366, 0.0052826134487986565, 0.004688893910497427, 0.009720991365611553, 3.766113513847813e-05, 0.002997400937601924, 0.004899767693132162, 0.018005043268203735, 0.001260173856280744, 0.0003668417630251497, 0.012433494441211224, 0.00045144310570321977, 0.003391218837350607, 0.020106714218854904, 0.19821509718894958, 0.46908873319625854, 0.017118901014328003, 0.0353948138654232, 0.0013357715215533972, 0.0015932428650557995, 0.0007226284360513091, 0.0009997349698096514, 0.0010741117876023054, 0.0007789263036102057, 0.0009929460939019918, 0.0008933164062909782, 0.0010579873342067003, 0.0010831294348463416, 0.0007985100382938981, 0.0005805372493341565, 0.05673344060778618, 0.0014012705069035292, 0.0037288616877049208, 0.05932235345244408, 0.0023565914016216993, 0.0028910674154758453, 0.008196290582418442, 0.00030465921736322343, 0.006886681076139212, 7.020682096481323e-05, 0.0004830199177376926, 0.005090724676847458, 0.005531015805900097, 0.06377409398555756, 0.007011942565441132, 0.016523122787475586, 0.0003841569123324007, 0.00010543565440457314, 0.00037988898111507297, 6.264634430408478e-05, 0.00020449547446332872, 0.0006444432656280696, 0.0029279529117047787, 0.27126479148864746, 0.0017348292749375105, 0.0015825654845684767, 0.018547138199210167, 0.005182810127735138, 0.0018306536367163062, 0.0004157883522566408, 0.003919093869626522, 0.006055315490812063, 0.0012408507755026221, 0.059457436203956604, 0.0007746179471723735, 6.475222471635789e-05, 3.602526703616604e-05, 0.0016470623668283224, 0.00170350749976933]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "epsilon = 1e-8\n",
    "\n",
    "print(output_clean[idx_attach].argmax(dim=1))\n",
    "\n",
    "\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "result_clean=[]\n",
    "for node_id in idx_train[:300]:\n",
    "    node_id = node_id.item()\n",
    "    subset, edge_index, mapping, edge_mask = k_hop_subgraph(node_id, 2, poison_edge_index, relabel_nodes=False)\n",
    "    loop_edges = edge_index[:, edge_index[0] == node_id]\n",
    "    non_loop_edges = edge_index[:, edge_index[0] != node_id]\n",
    "\n",
    "    selected_x = poison_x[subset]\n",
    "    \n",
    "    for i in range(loop_edges.size(1)):\n",
    "        # Current loop edge to remove\n",
    "        current_loop_edge = loop_edges[:, i]\n",
    "\n",
    "        # Find indices of the current loop edge and its reverse\n",
    "        forward_edge_mask = (edge_index[0] == current_loop_edge[0]) & (edge_index[1] == current_loop_edge[1])\n",
    "        reverse_edge_mask = (edge_index[0] == current_loop_edge[1]) & (edge_index[1] == current_loop_edge[0])\n",
    "\n",
    "        # Combine masks for forward and reverse edges\n",
    "        combined_mask = forward_edge_mask | reverse_edge_mask\n",
    "\n",
    "        # Remove both forward and reverse edges from the graph\n",
    "        modified_edge_index = edge_index[:, ~combined_mask]\n",
    "\n",
    "        edge_weights = torch.ones(modified_edge_index.size(1), dtype=torch.float, device=device)\n",
    "\n",
    "        output, x = test_model(poison_x, modified_edge_index, edge_weights)\n",
    "        output = output[node_id]\n",
    "        output = torch.exp(output)\n",
    "        output += epsilon\n",
    "        # print(output)\n",
    "        # print(output_clean[node_id])\n",
    "        deviation = F.kl_div(output.log(), output_clean[node_id], reduce=False)\n",
    "        result_clean.append(deviation.mean().item())\n",
    "        # print(deviation.mean().item())\n",
    "print(result_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2977380752563477, 0.950320839881897, 0.37811070680618286, 0.07882420718669891, 1.4903225898742676, 0.8596345782279968, 1.0516297817230225, 0.48909837007522583, 0.788267970085144, 0.4453601837158203, 1.1475379467010498, 0.45884519815444946, 1.3244860172271729, 0.9546791911125183, 0.07504454255104065, 0.3208126127719879, 0.8683804273605347, 1.2308802604675293, 0.41911572217941284, 0.309292733669281, 0.6054389476776123, 0.3337344527244568, 0.9251076579093933, 0.9914975166320801, 1.2147763967514038, 1.4215353727340698, 0.047294892370700836, 2.2077574729919434, 1.5065945386886597, 0.45738351345062256, 0.8448051810264587, 1.3847031593322754, 1.9852842092514038, 0.2659023404121399, 2.203679084777832, 1.2907702922821045, 1.3443453311920166, 0.9638511538505554, 1.0708000659942627, 1.1990312337875366, 0.5467737913131714, 0.057270631194114685, 1.3864479064941406, 1.1133534908294678, 0.3127886652946472, 0.8844665288925171, 2.172104597091675, 0.9507893919944763, 0.5689969062805176, 0.7490334510803223, 1.2811367511749268, 1.2578036785125732, 0.10612934827804565, 1.1469602584838867, 0.9662535190582275, 1.0326588153839111, 1.0911824703216553, 1.3632395267486572, 1.1137620210647583, 0.6100517511367798, 0.7303030490875244, 2.1706271171569824, 0.9553132057189941, 0.8910871744155884, 0.2239769548177719, 0.9893349409103394, 1.0092839002609253, 0.3751252591609955, 0.37292778491973877, 1.1987627744674683, 0.7987072467803955, 0.8191410303115845, 0.886060893535614, 0.47938117384910583, 2.0415923595428467, 0.8809616565704346, 0.7678511142730713, 3.0774669647216797, 0.8783612251281738, 0.7303192019462585, 1.0855787992477417, 2.095139503479004, 0.6585174798965454, 0.4246842861175537, 0.6981054544448853, 0.7094926238059998, 1.6530077457427979, 1.633575201034546, 1.6109274625778198, 1.8749198913574219, 0.5203888416290283, 0.8719357252120972, 0.18485435843467712, 0.21331928670406342, 1.2680003643035889, 1.0979347229003906, 0.8347844481468201]\n"
     ]
    }
   ],
   "source": [
    "result_trigger = []\n",
    "for node_id in idx_attach:\n",
    "    node_id = node_id.item()\n",
    "    subset, edge_index, mapping, edge_mask = k_hop_subgraph(node_id, 2, poison_edge_index, relabel_nodes=False)\n",
    "    loop_edges = edge_index[:, edge_index[0] == node_id]\n",
    "    non_loop_edges = edge_index[:, edge_index[0] != node_id]\n",
    "\n",
    "    selected_x = poison_x[subset]\n",
    "    \n",
    "    for i in range(loop_edges.size(1)):\n",
    "        # Current loop edge to remove\n",
    "        current_loop_edge = loop_edges[:, i]\n",
    "\n",
    "        # Find indices of the current loop edge and its reverse\n",
    "        forward_edge_mask = (edge_index[0] == current_loop_edge[0]) & (edge_index[1] == current_loop_edge[1])\n",
    "        reverse_edge_mask = (edge_index[0] == current_loop_edge[1]) & (edge_index[1] == current_loop_edge[0])\n",
    "\n",
    "        # Combine masks for forward and reverse edges\n",
    "        combined_mask = forward_edge_mask | reverse_edge_mask\n",
    "\n",
    "        # Remove both forward and reverse edges from the graph\n",
    "        modified_edge_index = edge_index[:, ~combined_mask]\n",
    "\n",
    "        edge_weights = torch.ones(modified_edge_index.size(1), dtype=torch.float, device=device)\n",
    "\n",
    "        output, x = test_model(poison_x, modified_edge_index, edge_weights)\n",
    "        output = output[node_id]\n",
    "        output = torch.exp(output)\n",
    "        output += epsilon\n",
    "        # print(output)\n",
    "        # print(output_clean[node_id])\n",
    "        deviation = F.kl_div(output.log(), output_clean[node_id], reduce=False)\n",
    "        \n",
    "        if loop_edges[:,i][1]>len(data.x):\n",
    "            # print(loop_edges[:,i][1])\n",
    "            result_trigger.append(deviation.mean().item())\n",
    "            \n",
    "        # else:\n",
    "        # print(deviation.mean().item())\n",
    "            # result_clean.append(deviation.mean().item())\n",
    "\n",
    "        # result_trigger.append(deviation.mean().item())\n",
    "        # print(deviation.mean().item())\n",
    "print(result_trigger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "0.047294892370700836\n",
      "3.0774669647216797\n",
      "[3.0774669647216797, 2.2077574729919434, 2.203679084777832, 2.172104597091675, 2.1706271171569824, 2.095139503479004, 2.0415923595428467, 1.9852842092514038, 1.8749198913574219, 1.6530077457427979, 1.633575201034546, 1.6109274625778198, 1.5065945386886597, 1.4903225898742676, 1.4215353727340698, 1.3864479064941406, 1.3847031593322754, 1.3632395267486572, 1.3443453311920166, 1.3244860172271729, 1.2977380752563477, 1.2907702922821045, 1.2811367511749268, 1.2680003643035889, 1.2578036785125732, 1.2308802604675293, 1.2147763967514038, 1.1990312337875366, 1.1987627744674683, 1.1475379467010498, 1.1469602584838867, 1.1137620210647583, 1.1133534908294678, 1.0979347229003906, 1.0911824703216553, 1.0855787992477417, 1.0708000659942627, 1.0516297817230225, 1.0326588153839111, 1.0092839002609253, 0.9914975166320801, 0.9893349409103394, 0.9662535190582275, 0.9638511538505554, 0.9553132057189941, 0.9546791911125183, 0.9507893919944763, 0.950320839881897, 0.9251076579093933, 0.8910871744155884, 0.886060893535614, 0.8844665288925171, 0.8809616565704346, 0.8783612251281738, 0.8719357252120972, 0.8683804273605347, 0.8596345782279968, 0.8448051810264587, 0.8347844481468201, 0.8191410303115845, 0.7987072467803955, 0.788267970085144, 0.7678511142730713, 0.7490334510803223, 0.7303192019462585, 0.7303030490875244, 0.7094926238059998, 0.6981054544448853, 0.6585174798965454, 0.6100517511367798, 0.6054389476776123, 0.5689969062805176, 0.5467737913131714, 0.5203888416290283, 0.48909837007522583, 0.47938117384910583, 0.45884519815444946, 0.45738351345062256, 0.4453601837158203, 0.4246842861175537, 0.41911572217941284, 0.37811070680618286, 0.3751252591609955, 0.37292778491973877, 0.3337344527244568, 0.3208126127719879, 0.3127886652946472, 0.309292733669281, 0.2659023404121399, 0.2239769548177719, 0.21331928670406342, 0.18485435843467712, 0.10612934827804565, 0.07882420718669891, 0.07504454255104065, 0.057270631194114685, 0.047294892370700836]\n",
      "0.8452873229980469\n",
      "[0.8452873229980469, 0.46908873319625854, 0.45397529006004333, 0.39428645372390747, 0.3058874309062958, 0.27126479148864746, 0.23698624968528748, 0.23549330234527588, 0.22562208771705627, 0.19821509718894958, 0.16468475759029388, 0.1626230776309967, 0.15798304975032806, 0.15605990588665009, 0.15517204999923706, 0.14709840714931488, 0.13199907541275024, 0.1285494714975357, 0.12091435492038727, 0.1181253045797348, 0.10997682064771652, 0.10888790339231491, 0.10541337728500366, 0.0989408940076828, 0.09543657302856445, 0.0949375256896019, 0.09301000833511353, 0.0887475460767746, 0.08828593790531158, 0.08671317994594574, 0.08344726264476776, 0.08251415938138962, 0.07781189680099487, 0.07422113418579102, 0.07214256376028061, 0.07044804096221924, 0.06973324716091156, 0.06893835961818695, 0.06377409398555756, 0.059457436203956604, 0.05944450944662094, 0.05932235345244408, 0.058763593435287476, 0.05673344060778618, 0.05660196393728256, 0.056039124727249146, 0.05437513440847397, 0.05365464836359024, 0.053184881806373596, 0.0507669523358345, 0.04965854808688164, 0.04716971516609192, 0.04685632884502411, 0.04624851047992706, 0.043670654296875, 0.04351023584604263, 0.04212063178420067, 0.04116341471672058, 0.040045447647571564, 0.03930558264255524, 0.03764686733484268, 0.03761085495352745, 0.036510270088911057, 0.03583022579550743, 0.0353948138654232, 0.03534041345119476, 0.03482576832175255, 0.03380881994962692, 0.033776942640542984, 0.033399730920791626, 0.03218050301074982, 0.032053567469120026, 0.031877972185611725, 0.031830161809921265, 0.03158973529934883, 0.030067872256040573, 0.030044924467802048, 0.029695263132452965, 0.02927914634346962, 0.02895299158990383, 0.02864738367497921, 0.02845669351518154, 0.02712632343173027, 0.02691934071481228, 0.026439081877470016, 0.025424635037779808, 0.02529364824295044, 0.025092264637351036, 0.025060251355171204, 0.02505088970065117, 0.025042738765478134, 0.024205941706895828, 0.024105532094836235, 0.02310021221637726, 0.023059062659740448, 0.02214047871530056, 0.021968945860862732, 0.021932348608970642, 0.021673373878002167, 0.021438507363200188, 0.02142976224422455, 0.021329626441001892, 0.02132401242852211, 0.021319735795259476, 0.021051213145256042, 0.020826175808906555, 0.020731236785650253, 0.020106714218854904, 0.01915142498910427, 0.018871277570724487, 0.01856725662946701, 0.018547138199210167, 0.018247123807668686, 0.018005043268203735, 0.017938120290637016, 0.017934104427695274, 0.017873939126729965, 0.017799189314246178, 0.017751451581716537, 0.01771436631679535, 0.01770838163793087, 0.017675762996077538, 0.01738925836980343, 0.017219139263033867, 0.017165374010801315, 0.017118901014328003, 0.016794469207525253, 0.016523122787475586, 0.01595868170261383, 0.015634283423423767, 0.01557090412825346, 0.015423203818500042, 0.015173858031630516, 0.015041433274745941, 0.014885833486914635, 0.014840466901659966, 0.014427796006202698, 0.013558171689510345, 0.013120274059474468, 0.013079771772027016, 0.013045619241893291, 0.01281379908323288, 0.012672824785113335, 0.012433494441211224, 0.012410445138812065, 0.012362468056380749, 0.012266352772712708, 0.012151236645877361, 0.012067924253642559, 0.012060848996043205, 0.011893751099705696, 0.011876314878463745, 0.011839285492897034, 0.011715668253600597, 0.011698096990585327, 0.011550615541636944, 0.011548742651939392, 0.01135165523737669, 0.011145289056003094, 0.01109316200017929, 0.01104792021214962, 0.01104554533958435, 0.010990560054779053, 0.010973840951919556, 0.010568353347480297, 0.010489106178283691, 0.01048105489462614, 0.010477746836841106, 0.010251887142658234, 0.010058814659714699, 0.010048206895589828, 0.010024234652519226, 0.010016153566539288, 0.00999265443533659, 0.009969423525035381, 0.009873703122138977, 0.009816944599151611, 0.009720991365611553, 0.009574085474014282, 0.00952940247952938, 0.009489640593528748, 0.009281855076551437, 0.009267836809158325, 0.00916844792664051, 0.009131960570812225, 0.00912520568817854, 0.00903724879026413, 0.009005775675177574, 0.008947080001235008, 0.008905110880732536, 0.008871125057339668, 0.00883572082966566, 0.008783127181231976, 0.008778548799455166, 0.00871358998119831, 0.008705477230250835, 0.008561825379729271, 0.008483554236590862, 0.008370107039809227, 0.008329765871167183, 0.008284727111458778, 0.008265666663646698, 0.008196290582418442, 0.008171649649739265, 0.008088277652859688, 0.00796530582010746, 0.007948133163154125, 0.00794350914657116, 0.007920949719846249, 0.0079050213098526, 0.007805362343788147, 0.007797807455062866, 0.007712667342275381, 0.007695416919887066, 0.007519137114286423, 0.007498142775148153, 0.007448092103004456, 0.007387779653072357, 0.007285071536898613, 0.007262767758220434, 0.007190982811152935, 0.007190041244029999, 0.007188643328845501, 0.007187593728303909, 0.007110933773219585, 0.007011942565441132, 0.006988149136304855, 0.006972655653953552, 0.006940255872905254, 0.006886681076139212, 0.006750961299985647, 0.0066883317194879055, 0.006672114133834839, 0.0065939477644860744, 0.0065888911485672, 0.006525847129523754, 0.006523183546960354, 0.0065186223946511745, 0.006477519869804382, 0.006444843020290136, 0.006444571074098349, 0.006422390695661306, 0.006414664443582296, 0.006392344832420349, 0.0063880858942866325, 0.006371429190039635, 0.0063416436314582825, 0.006276953034102917, 0.006231979932636023, 0.006216615438461304, 0.006174619309604168, 0.006137275602668524, 0.006077483296394348, 0.006055315490812063, 0.00601041316986084, 0.005985046736896038, 0.005959102418273687, 0.005916088819503784, 0.005842546932399273, 0.0057702334597706795, 0.005763049237430096, 0.0056307073682546616, 0.005630414001643658, 0.0055937133729457855, 0.005566011182963848, 0.005531015805900097, 0.005515966098755598, 0.005513550713658333, 0.005497653968632221, 0.005483299493789673, 0.005462120287120342, 0.005419475492089987, 0.005416497588157654, 0.005402890499681234, 0.005397725850343704, 0.005397190805524588, 0.005389537662267685, 0.005386382341384888, 0.005384269170463085, 0.005353820975869894, 0.005350057035684586, 0.005320447497069836, 0.005319739691913128, 0.0053048222325742245, 0.0052826134487986565, 0.00527558010071516, 0.0052675469778478146, 0.005256150849163532, 0.005242206156253815, 0.005241956561803818, 0.005232859402894974, 0.005224573891609907, 0.005208591930568218, 0.005182810127735138, 0.005151510238647461, 0.005125766154378653, 0.005090724676847458, 0.005087519995868206, 0.005065766628831625, 0.00506085529923439, 0.00505482405424118, 0.005054491572082043, 0.004975646734237671, 0.004964575171470642, 0.004935996141284704, 0.004903356544673443, 0.004899767693132162, 0.004896844737231731, 0.00488387793302536, 0.004845199640840292, 0.004839576315134764, 0.004706816282123327, 0.004688893910497427, 0.004615139216184616, 0.004596962593495846, 0.004584181122481823, 0.004550380166620016, 0.004519566893577576, 0.004509091377258301, 0.004483354743570089, 0.004448199179023504, 0.004447107668966055, 0.004438964184373617, 0.004433175083249807, 0.004406226333230734, 0.0043861148878932, 0.004327506758272648, 0.004278404172509909, 0.004217013716697693, 0.004207540303468704, 0.004178185015916824, 0.004168556537479162, 0.004162271972745657, 0.004137189593166113, 0.004056519828736782, 0.004039580933749676, 0.004014169331640005, 0.003971288911998272, 0.00396651541814208, 0.003958342131227255, 0.0039554741233587265, 0.003921343944966793, 0.003919093869626522, 0.0039036828093230724, 0.003890346735715866, 0.00388411246240139, 0.003880530595779419, 0.0038289863150566816, 0.0038100332021713257, 0.0037781584542244673, 0.003758107777684927, 0.0037528998218476772, 0.0037483673077076674, 0.0037288616877049208, 0.00366220879368484, 0.003572138724848628, 0.0035539008677005768, 0.003523975145071745, 0.0035229537170380354, 0.003506205976009369, 0.003501353319734335, 0.003493125317618251, 0.003468173323199153, 0.0034361444413661957, 0.003391218837350607, 0.003389606950804591, 0.003379425033926964, 0.003362248418852687, 0.0033347855787724257, 0.0033137935679405928, 0.0032942357938736677, 0.003294175025075674, 0.003288350999355316, 0.0032866261899471283, 0.0032437294721603394, 0.0032170279882848263, 0.003210879862308502, 0.003207097528502345, 0.0032069049775600433, 0.003193418262526393, 0.0031892559491097927, 0.0031699712853878736, 0.0031474034767597914, 0.0031245104037225246, 0.0030905157327651978, 0.003079160815104842, 0.003063549753278494, 0.0030412774067372084, 0.0030096869450062513, 0.002997400937601924, 0.002983370330184698, 0.0029625201132148504, 0.0029611042700707912, 0.0029591615311801434, 0.0029439318459481, 0.002941615879535675, 0.0029359832406044006, 0.0029321364127099514, 0.0029279529117047787, 0.0028981990180909634, 0.0028910674154758453, 0.0028823267202824354, 0.002874041674658656, 0.002870639320462942, 0.002849420066922903, 0.002842262387275696, 0.0028348814230412245, 0.002823007060214877, 0.0028144842945039272, 0.002804623683914542, 0.002804212272167206, 0.002800112124532461, 0.0027908484917134047, 0.0027852128259837627, 0.0027612075209617615, 0.0027571420650929213, 0.002753760665655136, 0.002748283324763179, 0.0027185827493667603, 0.002710620639845729, 0.0027092844247817993, 0.0026245564222335815, 0.0026110392063856125, 0.0025922581553459167, 0.0025809488724917173, 0.0025768927298486233, 0.002572012599557638, 0.002571260090917349, 0.0025628507137298584, 0.002554347738623619, 0.0025472473353147507, 0.0025427553337067366, 0.002486536977812648, 0.0024865109007805586, 0.0024678311310708523, 0.0024653549771755934, 0.002462349832057953, 0.002425695536658168, 0.0024114656262099743, 0.002394114388152957, 0.0023810975253582, 0.002379582729190588, 0.0023565914016216993, 0.0023073290940374136, 0.002294667763635516, 0.0022773544769734144, 0.0022675693035125732, 0.0022662929259240627, 0.002207896439358592, 0.002197394846007228, 0.002187289297580719, 0.0021649114787578583, 0.0021593845449388027, 0.0021368018351495266, 0.0021331775933504105, 0.0021164182107895613, 0.0021012327633798122, 0.0020788933616131544, 0.0020605388563126326, 0.002046257257461548, 0.0020443457178771496, 0.0020404185634106398, 0.002024711575359106, 0.0020209222566336393, 0.0019944510422647, 0.0019880011677742004, 0.001986425369977951, 0.001980528235435486, 0.0019710685592144728, 0.0019642352126538754, 0.001958062406629324, 0.0019493898143991828, 0.001930552301928401, 0.001926568103954196, 0.0019245899748057127, 0.0019236467778682709, 0.0019093155860900879, 0.0019061823841184378, 0.0018990486860275269, 0.0018885508179664612, 0.0018878281116485596, 0.001876838505268097, 0.0018691237783059478, 0.0018671900033950806, 0.0018648518016561866, 0.0018627243116497993, 0.001853129593655467, 0.0018306536367163062, 0.0018202252686023712, 0.0018194864969700575, 0.0018128815572708845, 0.0018081516027450562, 0.0018051385413855314, 0.0017830997239798307, 0.001773939235135913, 0.0017735952278599143, 0.0017630060901865363, 0.001739799976348877, 0.0017362283542752266, 0.0017348292749375105, 0.001733369193971157, 0.0017265044152736664, 0.0017259170999750495, 0.001716994447633624, 0.0017143762670457363, 0.00170350749976933, 0.0016943620285019279, 0.00169319414999336, 0.001682595699094236, 0.0016818344593048096, 0.0016699049156159163, 0.0016666434239596128, 0.0016624806448817253, 0.0016596106579527259, 0.0016555053880438209, 0.0016470623668283224, 0.0016409903764724731, 0.0016402493929490447, 0.0016369856894016266, 0.0016235820949077606, 0.0016226371517404914, 0.0016096855979412794, 0.0015932428650557995, 0.0015825654845684767, 0.0015818167012184858, 0.0015791244804859161, 0.0015765668358653784, 0.0015759698580950499, 0.0015743182739242911, 0.0015623013023287058, 0.0015439571579918265, 0.0015316655626520514, 0.0015296190977096558, 0.0015225758543238044, 0.0015076672425493598, 0.0015061249723657966, 0.0015015329699963331, 0.0014976536622270942, 0.0014796145260334015, 0.0014780325582250953, 0.0014738594181835651, 0.0014521268894895911, 0.0014493981143459678, 0.0014442838728427887, 0.0014442622195929289, 0.001437778351828456, 0.0014372393488883972, 0.0014308288227766752, 0.001429407624527812, 0.001423930749297142, 0.0014079747488722205, 0.0014037378132343292, 0.0014022467657923698, 0.0014012705069035292, 0.0013963577803224325, 0.001390760182403028, 0.0013892899733036757, 0.0013884585350751877, 0.001381687237881124, 0.001379994093440473, 0.0013764237519353628, 0.0013761818408966064, 0.001375702559016645, 0.0013627060689032078, 0.0013473983854055405, 0.0013421674957498908, 0.0013357715215533972, 0.0013308189809322357, 0.0013091026339679956, 0.0013071883004158735, 0.0012966364156454802, 0.0012907256605103612, 0.0012891588266938925, 0.0012845546007156372, 0.0012817507376894355, 0.0012794740032404661, 0.0012781480327248573, 0.0012773554772138596, 0.001269738539122045, 0.0012688356218859553, 0.001260173856280744, 0.001256374642252922, 0.0012560015311464667, 0.0012514725094661117, 0.0012458860874176025, 0.0012408507755026221, 0.0012266449630260468, 0.0012196673778817058, 0.0012166997184976935, 0.0012142136693000793, 0.0012037516571581364, 0.0012037053238600492, 0.0011878997320309281, 0.001184128224849701, 0.0011761540081351995, 0.001172588556073606, 0.001156594487838447, 0.0011299442267045379, 0.001127593219280243, 0.0011258175363764167, 0.0011167488992214203, 0.0011128647020086646, 0.0011113410582765937, 0.0011059856042265892, 0.001105066272430122, 0.0011006768327206373, 0.0010934645542874932, 0.0010917950421571732, 0.0010911941062659025, 0.0010892925783991814, 0.0010831294348463416, 0.0010812627151608467, 0.0010754754766821861, 0.0010741117876023054, 0.0010726540349423885, 0.0010692080250009894, 0.0010667850729078054, 0.0010587995639070868, 0.0010579873342067003, 0.00105767953209579, 0.0010524317622184753, 0.0010513239540159702, 0.001039806753396988, 0.0010381669271737337, 0.001037518261000514, 0.0010373815894126892, 0.0010362789034843445, 0.001034339307807386, 0.0010309964418411255, 0.0010264904703944921, 0.0010194405913352966, 0.0010192515328526497, 0.001017085975036025, 0.0010158134391531348, 0.001014903886243701, 0.0010097710182890296, 0.0010092004667967558, 0.0009997349698096514, 0.0009971149265766144, 0.0009958971058949828, 0.0009955255081877112, 0.000993217690847814, 0.000993196270428598, 0.0009929460939019918, 0.0009904224425554276, 0.000982046127319336, 0.0009798003593459725, 0.0009758942760527134, 0.0009688455611467361, 0.0009662415832281113, 0.0009633737499825656, 0.0009619832853786647, 0.0009519855375401676, 0.0009458474814891815, 0.0009336099028587341, 0.0009289036388508976, 0.000922083854675293, 0.0009207464754581451, 0.0009206384420394897, 0.0009079470182769, 0.0009066542843356729, 0.0009034226532094181, 0.0009027744526974857, 0.0009024410392157733, 0.0008933164062909782, 0.0008906055008992553, 0.0008903585840016603, 0.0008876671781763434, 0.000886362511664629, 0.0008834898471832275, 0.0008830096339806914, 0.0008757133036851883, 0.0008755940943956375, 0.0008740996709093451, 0.0008686287328600883, 0.000868380069732666, 0.0008641568711027503, 0.0008570521022193134, 0.0008507728343829513, 0.0008504875004291534, 0.0008454391499981284, 0.0008343883673660457, 0.000833685218822211, 0.0008311764104291797, 0.0008311571436934173, 0.0008290546829812229, 0.0008278461173176765, 0.0008255988359451294, 0.0008211792446672916, 0.0008109025657176971, 0.0008092783391475677, 0.0008083700085990131, 0.0007985100382938981, 0.0007930429419502616, 0.0007924862438812852, 0.0007902762736193836, 0.0007824985077604651, 0.0007789263036102057, 0.0007746179471723735, 0.0007732618832960725, 0.0007669913466088474, 0.0007627207669429481, 0.0007592166657559574, 0.0007529035210609436, 0.0007440149784088135, 0.0007407417288050056, 0.0007310050423257053, 0.0007266447646543384, 0.0007226284360513091, 0.0007206543232314289, 0.0007185991853475571, 0.0007114897016435862, 0.0007084285607561469, 0.0006991479313001037, 0.0006840887363068759, 0.0006808614125475287, 0.0006756882066838443, 0.0006747333100065589, 0.0006705591222271323, 0.0006689348956570029, 0.0006525072967633605, 0.0006523555493913591, 0.000645030289888382, 0.0006444432656280696, 0.0006434768438339233, 0.0006407536566257477, 0.0006392033537849784, 0.0006297355284914374, 0.000628102570772171, 0.0006220763316377997, 0.0006164952064864337, 0.0006103751948103309, 0.0006040520966053009, 0.0005985039169900119, 0.000595891266129911, 0.0005946165765635669, 0.0005896383663639426, 0.0005878942902199924, 0.0005850879242643714, 0.0005837364587932825, 0.0005820021033287048, 0.0005805372493341565, 0.000569172843825072, 0.0005679306341335177, 0.0005620146985165775, 0.0005583892925642431, 0.000557897612452507, 0.0005532832583412528, 0.0005520149134099483, 0.0005509071052074432, 0.0005494995857588947, 0.0005488644237630069, 0.0005436601932160556, 0.000535331666469574, 0.0005322446813806891, 0.0005302121862769127, 0.0005297847092151642, 0.0005276917363516986, 0.000526486779563129, 0.0005234020645730197, 0.0005207521608099341, 0.0005201517487876117, 0.0005167530616745353, 0.0005115941166877747, 0.0005037753726355731, 0.0004977569333277643, 0.0004963725805282593, 0.0004926262190565467, 0.000490769452881068, 0.0004884458030574024, 0.00048541295109316707, 0.0004830199177376926, 0.00047251791693270206, 0.00046594752348028123, 0.00046435496187768877, 0.00046118046157062054, 0.000458316266303882, 0.00045594945549964905, 0.00045393407344818115, 0.000452650710940361, 0.00045144310570321977, 0.0004510178114287555, 0.0004426426603458822, 0.0004398748278617859, 0.0004351884126663208, 0.00042880576802417636, 0.00042836740612983704, 0.0004247725009918213, 0.0004230508056934923, 0.0004200885887257755, 0.0004192435590084642, 0.0004161400720477104, 0.0004157883522566408, 0.00041556856012903154, 0.0004154158232267946, 0.0004123167018406093, 0.0004098033532500267, 0.00040963044739328325, 0.00040242698742076755, 0.0004022146458737552, 0.00039987158379517496, 0.00039276271127164364, 0.0003887477214448154, 0.0003881466982420534, 0.0003841569123324007, 0.0003802857827395201, 0.00037988898111507297, 0.0003792140632867813, 0.00037710307515226305, 0.00037534753209911287, 0.000375090487068519, 0.00037404545582830906, 0.00037327231257222593, 0.0003724205307662487, 0.0003671674057841301, 0.0003668417630251497, 0.00036584836198017, 0.0003642762894742191, 0.00035793831921182573, 0.00034593488089740276, 0.000342274724971503, 0.00033908835030160844, 0.0003375572559889406, 0.00033739954233169556, 0.000336979835992679, 0.0003350724873598665, 0.0003344242868479341, 0.0003337994567118585, 0.00033295550383627415, 0.0003312875924166292, 0.00032700476003810763, 0.00032699978328309953, 0.00032683712197467685, 0.00032485401607118547, 0.00032206004834733903, 0.0003218180499970913, 0.00031136241159401834, 0.00031053958809934556, 0.00030747056007385254, 0.0003052235988434404, 0.00030465921736322343, 0.00030410662293434143, 0.00030013424111530185, 0.0002989565837197006, 0.0002889741153921932, 0.0002846788556780666, 0.0002762571384664625, 0.00027546536875888705, 0.0002733722794800997, 0.0002639169688336551, 0.00026386789977550507, 0.00026164454175159335, 0.0002610346709843725, 0.00025841471506282687, 0.00025710463523864746, 0.0002570822834968567, 0.00025640492094680667, 0.000255143124377355, 0.0002546105533838272, 0.0002541939611546695, 0.000250181183218956, 0.00024138732987921685, 0.0002403374237474054, 0.00023401761427521706, 0.000231480851653032, 0.0002305302768945694, 0.0002260829060105607, 0.0002254511637147516, 0.00022459565661847591, 0.0002230083046015352, 0.00022268644534051418, 0.0002195859997300431, 0.00021812475461047143, 0.00021692723385058343, 0.00021535344421863556, 0.0002123707381542772, 0.00021114604896865785, 0.00020980618137400597, 0.000209323363378644, 0.0002063227293547243, 0.0002058073878288269, 0.00020449547446332872, 0.00020359535119496286, 0.00020195823162794113, 0.00020158695406280458, 0.00020072772167623043, 0.0001995234633795917, 0.00019681453704833984, 0.00019460669136606157, 0.00019457051530480385, 0.0001939241774380207, 0.00019244074064772576, 0.0001841516641434282, 0.00017979121184907854, 0.0001755108532961458, 0.00017343214130960405, 0.00017041651881299913, 0.00016892142593860626, 0.00016870505351107568, 0.00016855946159921587, 0.00016530719585716724, 0.00016292184591293335, 0.0001600061950739473, 0.00015072152018547058, 0.00014879570517223328, 0.00014412961900234222, 0.00014402717351913452, 0.00014035403728485107, 0.00013928224507253617, 0.00013877576566301286, 0.00013688206672668457, 0.00013486544776242226, 0.0001338507718173787, 0.00013192743062973022, 0.00012194675946375355, 0.00011962155986111611, 0.00011746794916689396, 0.00011617535346886143, 0.00011563363659661263, 0.00011429935693740845, 0.00011242678010603413, 0.00011151393118780106, 0.00011134396481793374, 0.00010737621778389439, 0.00010717951226979494, 0.00010693042713683099, 0.00010672211647033691, 0.00010543565440457314, 0.00010530806321185082, 9.666167170507833e-05, 9.485935879638419e-05, 9.39766614465043e-05, 9.274296462535858e-05, 9.118641901295632e-05, 9.113302076002583e-05, 8.905989670893177e-05, 8.852159226080403e-05, 8.638513827463612e-05, 8.187567436834797e-05, 7.925128738861531e-05, 7.674144580960274e-05, 7.457038009306416e-05, 7.184160494944081e-05, 7.020682096481323e-05, 7.000907498877496e-05, 6.880114960949868e-05, 6.475222471635789e-05, 6.42370869172737e-05, 6.264634430408478e-05, 6.128211680334061e-05, 6.0741713241441175e-05, 5.201933527132496e-05, 5.18440137966536e-05, 5.1585957407951355e-05, 5.147358024260029e-05, 5.135933679412119e-05, 4.922521111438982e-05, 4.8434361815452576e-05, 4.834961146116257e-05, 4.6510249376297e-05, 4.631529373000376e-05, 4.559507215162739e-05, 4.2549025238258764e-05, 4.018827894469723e-05, 3.95247116102837e-05, 3.885974729200825e-05, 3.824939994956367e-05, 3.8170685002114624e-05, 3.766113513847813e-05, 3.644661046564579e-05, 3.6332447052700445e-05, 3.602526703616604e-05, 3.591106360545382e-05, 3.5542354453355074e-05, 3.492025280138478e-05, 3.4265220165252686e-05, 3.2630654459353536e-05, 3.237587952753529e-05, 3.2159266993403435e-05, 3.141661727568135e-05, 3.14079225063324e-05, 3.0896044336259365e-05, 3.0637020245194435e-05, 2.995257636939641e-05, 2.800549191306345e-05, 2.7728403438231908e-05, 2.6984762371284887e-05, 2.673516792128794e-05, 2.662216684257146e-05, 2.5934987206710503e-05, 2.3534852516604587e-05, 2.1603365894407034e-05, 1.895284185593482e-05, 1.8949232980958186e-05, 1.8765711502055638e-05, 1.860000702436082e-05, 1.857026290963404e-05, 1.7774040315998718e-05, 1.7706461221678182e-05, 1.7676502466201782e-05, 1.764481930877082e-05, 1.740087100188248e-05, 1.710737524263095e-05, 1.6069312550825998e-05, 1.5159137547016144e-05, 1.496092136221705e-05, 1.2484614671848249e-05, 1.1459595043561421e-05, 1.0623868547554594e-05, 1.0401476174592972e-05, 9.354682333650999e-06, 9.194895028485917e-06, 9.041296834766399e-06, 8.875575076672249e-06, 8.669611816003453e-06, 8.558061381336302e-06, 8.466951840091497e-06, 8.4441253420664e-06, 8.332352081197314e-06, 8.302238711621612e-06, 8.269989848486148e-06, 8.238424015871715e-06, 8.177921699825674e-06, 8.173294190783054e-06, 7.782444299664348e-06, 7.603327503602486e-06, 7.596099749207497e-06, 7.571560672658961e-06, 7.530984930781415e-06, 7.5275092967785895e-06, 7.5176844802626874e-06, 7.475660822819918e-06, 7.342421213252237e-06, 7.310067303478718e-06, 7.290374014701229e-06, 7.233272299345117e-06, 7.035703220026335e-06, 6.6566572058945894e-06, 6.635367753915489e-06, 6.6287639128859155e-06, 6.545878477481892e-06, 6.457577455876162e-06, 6.435383511416148e-06, 6.287019459705334e-06, 6.258318080654135e-06, 5.981669346510898e-06, 5.740769665862899e-06, 5.713132850360125e-06, 5.653455446008593e-06, 5.6234448493341915e-06, 5.610321295534959e-06, 5.609118488791864e-06, 5.231413524597883e-06, 5.168161351321032e-06, 5.163485184311867e-06, 5.107329343445599e-06, 5.085234988655429e-06, 5.014335329178721e-06, 4.9742229748517275e-06, 4.731858552986523e-06, 4.4831349441665225e-06, 4.3222489694016986e-06, 4.3134132283739746e-06, 4.267084932507714e-06, 3.971780643041711e-06, 3.844810180453351e-06, 3.7458448787219822e-06, 3.613148464864935e-06, 3.533704784786096e-06, 2.918832933573867e-06, 2.918522568506887e-06, 2.7509704523254186e-06, 2.675825726328185e-06, 2.6508885184739484e-06, 2.528709501348203e-06, 2.5081731109821703e-06, 2.4576827399869217e-06, 2.363831299589947e-06, 2.3573279577249195e-06, 1.973162170543219e-06, 1.9365943444427103e-06, 1.864032469711674e-06, 1.7869073190013296e-06, 1.6222815020228154e-06, 1.5983048342604889e-06, 1.5699964706072933e-06, 1.4821756622040994e-06, 1.4003211390445358e-06, 1.363834599032998e-06, 1.3490692936102278e-06, 1.2024150919387466e-06, 8.597562555223703e-07, 7.816221909706655e-07, 7.021978376542393e-07, 5.777013711849577e-07, 5.160885621080524e-07, 4.988202704225841e-07, 4.339478323345247e-07, 3.733730409294367e-07, 2.6729929913926753e-07, 2.0947967982465343e-07, 1.1489222373484154e-07, 1.0920727788743534e-07, 1.0480289347469807e-07, 7.7222168215485e-08, 3.421640570877571e-08]\n"
     ]
    }
   ],
   "source": [
    "print(len(result_trigger))\n",
    "print(min(result_trigger))\n",
    "print(max(result_trigger))\n",
    "print(sorted(result_trigger,reverse=True))\n",
    "print(max(result_clean))\n",
    "print(sorted(result_clean,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure you have your data loaded in result_clean and result_trigger\n",
    "# Example: result_clean = [1, 2, 3], result_trigger = [3, 2, 1]\n",
    "# result_trigger = [x for x in result_trigger if x < 0.8 and x>0.2]\n",
    "# result_clean = [x for x in result_clean if x < 2 and x>0.2]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plt.hist(result_trigger, alpha=0.7, bins=10, label='Trigger Edge',density=True)\n",
    "# # plt.hist(result_trigger, alpha=0.7, bins=10, label='Trigger Data')\n",
    "\n",
    "# plt.hist(result_clean, alpha=0.7, bins=10, label='Clean Edge',density=True)\n",
    "# # plt.hist(result_clean, alpha=0.7, bins=10, label='Clean Data')\n",
    "\n",
    "\n",
    "# # plt.title('Histogram of Clean and Trigger Data')\n",
    "# plt.xlabel('Prediction Variance')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# # Save the plot before displaying it\n",
    "# plt.savefig('cora.pdf')\n",
    "\n",
    "# # Display the plot\n",
    "# plt.show()\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.hist(result_trigger, alpha=0.7, bins=10, label='Trigger Edges', density=True)\n",
    "plt.hist(result_clean, alpha=0.7, bins=10, label='Clean Edges', density=True)\n",
    "\n",
    "plt.xlabel('Prediction Variance',fontsize=16)\n",
    "plt.ylabel('Frequency',fontsize=16)\n",
    "\n",
    "# Adjust x and y ticks\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# Add a caption below the figure\n",
    "# plt.figtext(0.5, -0.05, 'Comparison of prediction variance due to trigger edges drop and clean edges drop.', wrap=True, horizontalalignment='center', fontsize=14)\n",
    "\n",
    "# Save the plot before displaying it\n",
    "plt.savefig('cora.pdf')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_clean=[]\n",
    "# for node_id in idx_train[:10000]:\n",
    "#     node_id = node_id.item()\n",
    "#     subset, edge_index, mapping, edge_mask = k_hop_subgraph(node_id, 2, poison_edge_index, relabel_nodes=False)\n",
    "#     loop_edges = edge_index[:, edge_index[0] == node_id]\n",
    "#     non_loop_edges = edge_index[:, edge_index[0] != node_id]\n",
    "\n",
    "#     selected_x = poison_x[subset]\n",
    "    \n",
    "#     for i in range(loop_edges.size(1)):\n",
    "#         # Current loop edge to remove\n",
    "#         current_loop_edge = loop_edges[:, i]\n",
    "\n",
    "#         # Find indices of the current loop edge and its reverse\n",
    "#         forward_edge_mask = (edge_index[0] == current_loop_edge[0]) & (edge_index[1] == current_loop_edge[1])\n",
    "#         reverse_edge_mask = (edge_index[0] == current_loop_edge[1]) & (edge_index[1] == current_loop_edge[0])\n",
    "\n",
    "#         # Combine masks for forward and reverse edges\n",
    "#         combined_mask = forward_edge_mask | reverse_edge_mask\n",
    "\n",
    "#         # Remove both forward and reverse edges from the graph\n",
    "#         modified_edge_index = edge_index[:, ~combined_mask]\n",
    "\n",
    "#         edge_weights = torch.ones(modified_edge_index.size(1), dtype=torch.float, device=device)\n",
    "\n",
    "#         output, x = test_model(poison_x, modified_edge_index, edge_weights)\n",
    "#         output = output[node_id]\n",
    "#         output = torch.exp(output)\n",
    "#         output += epsilon\n",
    "#         deviation = F.kl_div(output.log(), output_clean[node_id], reduce=False)\n",
    "#         result_clean.append(deviation.mean().item())\n",
    "#         print(deviation.mean().item())\n",
    "# print(result_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_trigger = []\n",
    "# for node_id in idx_attach:\n",
    "#     node_id = node_id.item()\n",
    "#     subset, edge_index, mapping, edge_mask = k_hop_subgraph(node_id, 2, poison_edge_index, relabel_nodes=False)\n",
    "#     loop_edges = edge_index[:, edge_index[0] == node_id]\n",
    "#     non_loop_edges = edge_index[:, edge_index[0] != node_id]\n",
    "\n",
    "#     selected_x = poison_x[subset]\n",
    "    \n",
    "#     for i in range(loop_edges.size(1)):\n",
    "#         # Current loop edge to remove\n",
    "#         current_loop_edge = loop_edges[:, i]\n",
    "\n",
    "#         # Find indices of the current loop edge and its reverse\n",
    "#         forward_edge_mask = (edge_index[0] == current_loop_edge[0]) & (edge_index[1] == current_loop_edge[1])\n",
    "#         reverse_edge_mask = (edge_index[0] == current_loop_edge[1]) & (edge_index[1] == current_loop_edge[0])\n",
    "\n",
    "#         # Combine masks for forward and reverse edges\n",
    "#         combined_mask = forward_edge_mask | reverse_edge_mask\n",
    "\n",
    "#         # Remove both forward and reverse edges from the graph\n",
    "#         modified_edge_index = edge_index[:, ~combined_mask]\n",
    "\n",
    "#         edge_weights = torch.ones(modified_edge_index.size(1), dtype=torch.float, device=device)\n",
    "\n",
    "#         output, x = test_model(poison_x, modified_edge_index, edge_weights)\n",
    "#         output = output[node_id]\n",
    "#         output = torch.exp(output)\n",
    "#         output += epsilon\n",
    "#         deviation = F.kl_div(output.log(), output_clean[node_id], reduce=False)\n",
    "        \n",
    "#         if loop_edges[:,i][1]>len(data.x):\n",
    "#             result_trigger.append(deviation.mean().item())\n",
    "#         else:\n",
    "#             print(deviation.mean().item())\n",
    "#             # result_clean.append(deviation.mean().item())\n",
    "\n",
    "#         result_trigger.append(deviation.mean().item())\n",
    "#         print(deviation.mean().item())\n",
    "# print(result_trigger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Ensure you have your data loaded in result_clean and result_trigger\n",
    "# # Example: result_clean = [1, 2, 3], result_trigger = [3, 2, 1]\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "\n",
    "# plt.hist(result_trigger, alpha=0.7, bins=10, label='Trigger Data',density=True)\n",
    "# # plt.hist(result_trigger, alpha=0.7, bins=10, label='Trigger Data')\n",
    "\n",
    "# plt.hist(result_clean, alpha=0.7, bins=10, label='Clean Data',density=True)\n",
    "# # plt.hist(result_clean, alpha=0.7, bins=10, label='Clean Data')\n",
    "\n",
    "\n",
    "# plt.title('Histogram of Clean and Trigger Data')\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "poison_labels[idx_attach] = args.target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx_attach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2], device='cuda:2')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on clean test nodes: 0.0000\n"
     ]
    }
   ],
   "source": [
    "## retrain a model on purified graph ##\n",
    "\n",
    "# labels for target poisoned node before purified #\n",
    "print(poison_labels[idx_attach])\n",
    "\n",
    "# purifying #\n",
    "# for idx in index_of_less_robust:\n",
    "#     poison_labels[bkd_tn_nodes[idx]]=data.y[bkd_tn_nodes[idx]]\n",
    "# # poison_labels[idx_attach] = data.y[idx_attach]\n",
    "\n",
    "# # labels for target poisoned node after purified #\n",
    "# print(poison_labels[idx_attach])\n",
    "\n",
    "# retrain a model #s\n",
    "test_model = model_construct(args,args.test_model,data,device).to(device) \n",
    "test_model.fit(poison_x,poison_edge_index, poison_edge_weights, poison_labels, bkd_tn_nodes, idx_val,train_iters=args.epochs,verbose=False, finetune=True, attach=index_of_less_robust)\n",
    "\n",
    "## test model on purified graph (poisoned target node) ##\n",
    "clean_acc = test_model.test(poison_x,poison_edge_index, poison_edge_weights,poison_labels,idx_attach)\n",
    "\n",
    "print(\"accuracy on clean test nodes: {:.4f}\".format(clean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR: 0.0010\n",
      "Flip ASR: 0.0000/1198 nodes\n",
      "CA: 0.8387\n"
     ]
    }
   ],
   "source": [
    "# add a trigger detector #\n",
    "# assumption: backdoor attack's success is based on trigger pattern #\n",
    "# 1. outlier, trigger different to each other #\n",
    "# 2. in distribution, trigger similar to each other #\n",
    "# # in case, model trained on clean graph learn attack pattern #\n",
    "induct_edge_index = torch.cat([poison_edge_index,mask_edge_index],dim=1)\n",
    "induct_edge_weights = torch.cat([poison_edge_weights,torch.ones([mask_edge_index.shape[1]],dtype=torch.float,device=device)])\n",
    "induct_x, induct_edge_index,induct_edge_weights = model.inject_trigger(idx_atk,poison_x,induct_edge_index,induct_edge_weights,device)\n",
    "# induct_x, induct_edge_index,induct_edge_weights = model.inject_trigger(idx_attach,poison_x,induct_edge_index,induct_edge_weights,device)\n",
    "induct_x, induct_edge_index,induct_edge_weights = induct_x.clone().detach(), induct_edge_index.clone().detach(),induct_edge_weights.clone().detach()\n",
    "\n",
    "output, x = test_model(induct_x,induct_edge_index,induct_edge_weights)\n",
    "train_attach_rate = (output.argmax(dim=1)[idx_atk]==args.target_class).float().mean()\n",
    "# train_attach_rate = (output.argmax(dim=1)[idx_attach]==args.target_class).float().mean()\n",
    "print(\"ASR: {:.4f}\".format(train_attach_rate))\n",
    "asr = train_attach_rate\n",
    "flip_idx_atk = idx_atk[(data.y[idx_atk] != args.target_class).nonzero().flatten()]\n",
    "flip_asr = (output.argmax(dim=1)[flip_idx_atk]==args.target_class).float().mean()\n",
    "print(\"Flip ASR: {:.4f}/{} nodes\".format(flip_asr,flip_idx_atk.shape[0]))\n",
    "ca = test_model.test(induct_x,induct_edge_index,induct_edge_weights,data.y,idx_clean_test)\n",
    "print(\"CA: {:.4f}\".format(ca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0], device='cuda:2')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.argmax(dim=1)[idx_atk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5123e-02, 1.7231e-02, 9.4765e-01],\n",
       "        [2.8908e-01, 2.1842e-01, 4.9249e-01],\n",
       "        [2.5662e-01, 6.6255e-01, 8.0834e-02],\n",
       "        [1.2321e-02, 9.0827e-01, 7.9408e-02],\n",
       "        [1.1209e-01, 2.5841e-02, 8.6207e-01],\n",
       "        [6.6457e-02, 4.9207e-01, 4.4148e-01],\n",
       "        [9.0467e-01, 4.0869e-02, 5.4457e-02],\n",
       "        [2.1579e-02, 1.0204e-01, 8.7638e-01],\n",
       "        [5.3362e-01, 8.7810e-02, 3.7857e-01],\n",
       "        [9.8310e-01, 5.2436e-03, 1.1656e-02],\n",
       "        [7.4625e-02, 7.9932e-01, 1.2605e-01],\n",
       "        [8.4768e-01, 6.9470e-02, 8.2854e-02],\n",
       "        [6.6169e-01, 2.6795e-02, 3.1151e-01],\n",
       "        [5.2977e-03, 7.3199e-03, 9.8738e-01],\n",
       "        [1.2480e-02, 2.6025e-02, 9.6150e-01],\n",
       "        [3.1993e-01, 3.2073e-01, 3.5935e-01],\n",
       "        [8.7365e-01, 4.6700e-02, 7.9652e-02],\n",
       "        [3.2145e-01, 5.4159e-01, 1.3696e-01],\n",
       "        [5.3858e-01, 5.6415e-02, 4.0500e-01],\n",
       "        [4.2634e-02, 1.6012e-01, 7.9724e-01],\n",
       "        [6.0744e-03, 1.3942e-02, 9.7998e-01],\n",
       "        [1.0885e-01, 1.2842e-02, 8.7830e-01],\n",
       "        [4.9193e-02, 5.6642e-01, 3.8439e-01],\n",
       "        [7.6071e-01, 7.5268e-02, 1.6402e-01],\n",
       "        [8.1028e-01, 8.0905e-02, 1.0882e-01],\n",
       "        [2.5686e-02, 3.3025e-01, 6.4407e-01],\n",
       "        [2.5197e-02, 8.9393e-01, 8.0876e-02],\n",
       "        [3.5452e-02, 8.1768e-01, 1.4687e-01],\n",
       "        [9.7415e-01, 9.3217e-03, 1.6525e-02],\n",
       "        [6.3953e-01, 2.9163e-01, 6.8841e-02],\n",
       "        [3.9080e-01, 3.9355e-01, 2.1565e-01],\n",
       "        [3.9101e-01, 2.3165e-01, 3.7734e-01],\n",
       "        [1.3066e-01, 5.0307e-01, 3.6626e-01],\n",
       "        [1.2517e-02, 3.1522e-02, 9.5596e-01],\n",
       "        [2.0677e-01, 2.9741e-01, 4.9582e-01],\n",
       "        [6.5180e-01, 8.0093e-02, 2.6811e-01],\n",
       "        [7.9930e-01, 5.7161e-02, 1.4354e-01],\n",
       "        [1.9434e-01, 5.0867e-02, 7.5480e-01],\n",
       "        [1.0070e-02, 1.1884e-02, 9.7805e-01],\n",
       "        [4.0745e-02, 8.2024e-01, 1.3902e-01],\n",
       "        [7.3768e-01, 7.5930e-02, 1.8639e-01],\n",
       "        [8.5407e-01, 7.8399e-02, 6.7535e-02],\n",
       "        [5.2671e-03, 9.7481e-03, 9.8498e-01],\n",
       "        [1.5904e-02, 4.4876e-01, 5.3534e-01],\n",
       "        [1.7138e-01, 8.2163e-01, 6.9888e-03],\n",
       "        [1.9550e-01, 4.1854e-01, 3.8596e-01],\n",
       "        [8.3834e-01, 1.1079e-01, 5.0873e-02],\n",
       "        [2.8051e-02, 6.5608e-01, 3.1586e-01],\n",
       "        [6.4599e-02, 8.2322e-02, 8.5308e-01],\n",
       "        [9.8217e-01, 1.1997e-02, 5.8326e-03],\n",
       "        [9.7396e-01, 1.4654e-02, 1.1387e-02],\n",
       "        [2.4218e-02, 6.4438e-01, 3.3141e-01],\n",
       "        [6.5916e-01, 4.4136e-02, 2.9671e-01],\n",
       "        [7.8164e-01, 8.1177e-02, 1.3719e-01],\n",
       "        [2.7218e-02, 9.2307e-01, 4.9708e-02],\n",
       "        [6.2929e-02, 5.5486e-02, 8.8158e-01],\n",
       "        [4.1101e-02, 8.4327e-01, 1.1563e-01],\n",
       "        [6.8631e-02, 4.2941e-02, 8.8843e-01],\n",
       "        [8.8728e-01, 3.8710e-02, 7.4006e-02],\n",
       "        [4.5361e-01, 3.6922e-01, 1.7717e-01],\n",
       "        [1.3254e-02, 9.2476e-01, 6.1986e-02],\n",
       "        [1.2776e-02, 9.3044e-01, 5.6780e-02],\n",
       "        [3.2092e-02, 7.8569e-01, 1.8222e-01],\n",
       "        [2.3999e-02, 8.6596e-01, 1.1004e-01],\n",
       "        [4.1988e-02, 6.3669e-01, 3.2132e-01],\n",
       "        [3.5188e-01, 4.3788e-02, 6.0433e-01],\n",
       "        [1.6022e-02, 9.0695e-02, 8.9328e-01],\n",
       "        [4.9302e-03, 1.2360e-01, 8.7147e-01],\n",
       "        [1.7431e-02, 2.8388e-02, 9.5418e-01],\n",
       "        [1.7534e-01, 3.0753e-01, 5.1713e-01],\n",
       "        [9.7511e-01, 2.4848e-02, 3.8164e-05],\n",
       "        [9.9973e-01, 2.1030e-04, 6.1760e-05],\n",
       "        [2.8206e-01, 6.6050e-01, 5.7442e-02],\n",
       "        [5.5441e-02, 6.7164e-01, 2.7292e-01],\n",
       "        [9.9847e-01, 9.4384e-04, 5.8300e-04],\n",
       "        [9.9373e-01, 2.2393e-03, 4.0297e-03],\n",
       "        [7.0738e-02, 1.9160e-01, 7.3766e-01],\n",
       "        [1.5641e-02, 7.4765e-01, 2.3671e-01],\n",
       "        [5.2853e-01, 2.7555e-01, 1.9591e-01],\n",
       "        [2.4014e-01, 3.5844e-01, 4.0142e-01],\n",
       "        [5.7233e-02, 4.4635e-01, 4.9642e-01],\n",
       "        [2.9251e-02, 9.1805e-01, 5.2701e-02],\n",
       "        [6.2605e-03, 9.7955e-01, 1.4193e-02],\n",
       "        [4.7761e-02, 6.9540e-01, 2.5684e-01],\n",
       "        [9.3423e-03, 9.6014e-01, 3.0522e-02],\n",
       "        [6.0871e-01, 1.7607e-01, 2.1522e-01],\n",
       "        [1.8124e-01, 4.8290e-02, 7.7047e-01],\n",
       "        [3.7597e-02, 8.0347e-01, 1.5894e-01],\n",
       "        [2.6899e-02, 8.5827e-01, 1.1483e-01],\n",
       "        [1.3544e-03, 9.9639e-01, 2.2596e-03],\n",
       "        [3.5710e-02, 7.1753e-01, 2.4676e-01],\n",
       "        [2.4657e-02, 7.3427e-01, 2.4107e-01],\n",
       "        [8.9201e-01, 5.2639e-02, 5.5356e-02],\n",
       "        [1.5423e-02, 9.4628e-01, 3.8300e-02],\n",
       "        [3.4547e-01, 6.2187e-01, 3.2661e-02],\n",
       "        [2.7203e-02, 8.5030e-01, 1.2249e-01],\n",
       "        [6.4428e-01, 1.3976e-01, 2.1596e-01]], device='cuda:2',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs=F.softmax(output[index_of_less_robust], dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9476, 0.2891, 0.6625, 0.9083, 0.8621, 0.4921, 0.9047, 0.8764, 0.5336,\n",
       "        0.9831, 0.7993, 0.8477, 0.6617, 0.9874, 0.9615, 0.3199, 0.8736, 0.5416,\n",
       "        0.5386, 0.7972, 0.9800, 0.8783, 0.5664, 0.7607, 0.8103, 0.6441, 0.8939,\n",
       "        0.8177, 0.9742, 0.2916, 0.3936, 0.2317, 0.3663, 0.9560, 0.2974, 0.6518,\n",
       "        0.7993, 0.7548, 0.9780, 0.8202, 0.1864, 0.8541, 0.9850, 0.5353, 0.8216,\n",
       "        0.1955, 0.8383, 0.6561, 0.0646, 0.9822, 0.9740, 0.3314, 0.2967, 0.7816,\n",
       "        0.9231, 0.8816, 0.8433, 0.8884, 0.8873, 0.3692, 0.9248, 0.9304, 0.7857,\n",
       "        0.8660, 0.6367, 0.6043, 0.8933, 0.8715, 0.9542, 0.5171, 0.0248, 0.9997,\n",
       "        0.6605, 0.6716, 0.9985, 0.9937, 0.7377, 0.7477, 0.1959, 0.3584, 0.4964,\n",
       "        0.9180, 0.9795, 0.6954, 0.9601, 0.6087, 0.1812, 0.8035, 0.8583, 0.9964,\n",
       "        0.7175, 0.7343, 0.8920, 0.9463, 0.6219, 0.8503, 0.6443],\n",
       "       device='cuda:2', grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[range(len(poison_labels[index_of_less_robust])), poison_labels[index_of_less_robust]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 1, 1, 2, 1, 0, 2, 0, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0,\n",
       "        0, 2, 1, 1, 0, 1, 1, 1, 2, 2, 1, 0, 0, 2, 2, 1, 2, 0, 2, 2, 1, 0, 0, 1,\n",
       "        0, 0, 0, 2, 2, 0, 1, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 0,\n",
       "        1, 1, 0, 0, 2, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0], device='cuda:2')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poison_labels[index_of_less_robust]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spurious",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
